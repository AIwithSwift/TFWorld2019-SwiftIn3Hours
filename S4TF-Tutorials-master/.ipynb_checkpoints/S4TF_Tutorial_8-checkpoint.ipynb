{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyCcF45zBQ3E"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors. [Licensed under the Apache License, Version 2.0](#scrollTo=y_UVSRtBBsJk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPII1rGR2rF9",
    "scrolled": true
   },
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "// https://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHI3vyhv5p85"
   },
   "source": [
    "# Image Classification using Swift for TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVi775ZJ2bsy"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/13lBsht3Wa4GjKKkA47JCrd54XikhNX2E\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"Link to be updated\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub link to be updated accordingly</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCxmvkku5R-v"
   },
   "source": [
    "In this Colab you will classify images of flowers. We'll build an image classifier using `Layer` and load data by creating training and validation tensors of images as well as their corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAcmWrRy512Q"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_IfI4an53t7"
   },
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "*   glob ‚Äî to read files and directory structure.\n",
    "*   numpy ‚Äî for some matrix math outside of TensorFlow.\n",
    "*   matplotlib.pyplot ‚Äî to plot the graph and display images in our training and validation data.\n",
    "*  PIL ‚Äî to view images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ektHrmri503Q"
   },
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import Foundation\n",
    "import Python\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "let np = Python.import(\"numpy\")  // Make numpy available using np.\n",
    "let subprocess = Python.import(\"subprocess\")\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let os = Python.import(\"os\")\n",
    "let glob = Python.import(\"glob\")\n",
    "let pil = Python.import(\"PIL\")\n",
    "let pilImageOps = Python.import(\"PIL.ImageOps\")\n",
    "let random = Python.import(\"random\")\n",
    "let sk = Python.import(\"skimage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3fcURSS6S_i"
   },
   "source": [
    "In order to build our image classifier, we can begin by downloading the flowers dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00tAtxan6dbo"
   },
   "outputs": [],
   "source": [
    "public extension String {\n",
    "    @discardableResult\n",
    "    func shell(_ args: String...) -> String {\n",
    "        let (task, pipe) = (Process(), Pipe())\n",
    "        task.executableURL = URL(fileURLWithPath: self)\n",
    "        (task.arguments, task.standardOutput) = (args, pipe)\n",
    "        do    { try task.run() }\n",
    "        catch { print(\"Unexpected error: \\(error).\") }\n",
    "\n",
    "        let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
    "        return String(data: data, encoding: String.Encoding.utf8) ?? \"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KT2rv2eX6d8b",
    "outputId": "27dde1b8-548f-4cf0-c2d4-eb76010396fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 292M\r\n",
      "-rw-r--r-- 1 root root 166K Aug 25 12:00 Autoencoder.ipynb\r\n",
      "-rw-r--r-- 1 root root 3.1K Oct 19 09:17 EnableIPythonDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 6.8K Oct 19 09:17 EnableJupyterDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 313K Aug 25 12:00 GAN(Generative Adversarial Network).ipynb\r\n",
      "-rw-r--r-- 1 root root 4.6K Oct 19 09:17 KernelCommunicator.swift\r\n",
      "-rw-r--r-- 1 root root  354 Aug 25 12:00 README.md\r\n",
      "-rw-r--r-- 1 root root  18K Aug 25 12:00 S4TF_Tutorial_1.ipynb\r\n",
      "-rw-r--r-- 1 root root  67K Aug 25 12:00 S4TF_Tutorial_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 577K Aug 25 12:00 S4TF_Tutorial_3.ipynb\r\n",
      "-rw-r--r-- 1 root root 572K Aug 25 12:00 S4TF_Tutorial_4.ipynb\r\n",
      "-rw-r--r-- 1 root root 820K Aug 25 12:00 S4TF_Tutorial_5.ipynb\r\n",
      "-rw-r--r-- 1 root root 137K Aug 25 12:00 S4TF_Tutorial_6.ipynb\r\n",
      "-rw-r--r-- 1 root root  27K Aug 25 12:00 S4TF_Tutorial_7.ipynb\r\n",
      "-rw-r--r-- 1 root root  34K Oct 23 03:33 S4TF_Tutorial_8.ipynb\r\n",
      "-rw-r--r-- 1 root root  65M Aug 25 12:00 cats_and_dogs_filtered.tar.gz\r\n",
      "drwxr-x--- 8 root root  256 Feb 10  2016 flower_photos\r\n",
      "-rw-r--r-- 1 root root 219M Oct 23 03:25 flower_photos.tgz\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "print(\"/bin/ls\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aonzsRRqoWZ9"
   },
   "source": [
    "In order to build our image classifier, we can begin by downloading the flowers dataset. We first need to download the archive version of the dataset and after the download, we unzip it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NldOzNbk_9xq"
   },
   "source": [
    "The  dataset we downloaded contains images of 5 types of flowers:\n",
    "\n",
    "1. Rose\n",
    "2. Daisy\n",
    "3. Dandelion\n",
    "4. Sunflowers\n",
    "5. Tulips\n",
    "\n",
    "So, let's create the labels for these 5 classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeDOH8TR_-xi"
   },
   "outputs": [],
   "source": [
    "let classNames = [\"roses\", \"daisy\", \"dandelion\", \"sunflowers\", \"tulips\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zN86uRrg7UDc"
   },
   "source": [
    "Also, the dataset we have downloaded has following directory structure:\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>flower_photos</b>\n",
    "|__ <b>diasy</b>\n",
    "|__ <b>dandelion</b>\n",
    "|__ <b>roses</b>\n",
    "|__ <b>sunflowers</b>\n",
    "|__ <b>tulips</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "SCombgoqB0hs",
    "outputId": "b4a3bb5d-51d8-471f-9140-c9c20776af11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14167534527_781ceb1b7a_n.jpg\r\n",
      "5512287917_9f5d3f0f98_n.jpg\r\n",
      "476857510_d2b30175de_n.jpg\r\n",
      "521762040_f26f2e08dd.jpg\r\n",
      "7320089276_87b544e341.jpg\r\n",
      "8008258043_5457dd254b_n.jpg\r\n",
      "721595842_bacd80a6ac.jpg\r\n",
      "8719756744_34a5a83976_n.jpg\r\n",
      "5110107234_12ddc0206b_m.jpg\r\n",
      "20773528301_008fcbc5a1_n.jpg\r\n"
     ]
    }
   ],
   "source": [
    "let filelist = try FileManager.default.contentsOfDirectory(atPath: \"./flower_photos/daisy\")\n",
    "for filename in filelist[0..<10] {\n",
    "    print(filename)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-ThzyQld-xv"
   },
   "source": [
    "Let's look at how many images we have in our directory for each flower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "SY9dXaFgBE4l",
    "outputId": "ab72d149-39f8-448f-9229-96d65808af83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images 3670\r\n",
      "roses 641\r\n",
      "sunflowers 699\r\n",
      "daisy 633\r\n",
      "tulips 799\r\n",
      "dandelion 898\r\n"
     ]
    }
   ],
   "source": [
    "let totalImages = glob.glob(\"flower_photos/*/**.jpg\")\n",
    "let daisyList = glob.glob(\"flower_photos/daisy/*.jpg\")\n",
    "let dandelionList = glob.glob(\"flower_photos/dandelion/*.jpg\")\n",
    "let rosesList = glob.glob(\"flower_photos/roses/*.jpg\")\n",
    "let sunflowersList = glob.glob(\"flower_photos/sunflowers/*.jpg\")\n",
    "let tulipsList = glob.glob(\"flower_photos/tulips/*.jpg\")\n",
    "\n",
    "print(\"Total Images \\(totalImages.count)\")\n",
    "print(\"roses \\(rosesList.count)\")\n",
    "print(\"sunflowers \\(sunflowersList.count)\")\n",
    "print(\"daisy \\(daisyList.count)\")\n",
    "print(\"tulips \\(tulipsList.count)\")\n",
    "print(\"dandelion \\(dandelionList.count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fOp3XH_7ngK"
   },
   "source": [
    "We'll now assign variables with the proper file path for the training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJVVxOUXAv8T"
   },
   "source": [
    "As you can see there are no folders containing training and validation data. Therefore, we will have to create our own training and validation set. Let's write some code that will do this.\n",
    "\n",
    "\n",
    "The code below creates a `trainList` and a `testList` list. It then copies the image paths from the original folders to these new lists such that 80% of the images go to the training set and 20% of the images go into the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Q-CK_BBQ1Yru",
    "outputId": "f1ed9f58-2bd7-4a41-ec41-fd3e86d288b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images 3670\r\n",
      "Train Images 2934\r\n",
      "Test Images 736\r\n"
     ]
    }
   ],
   "source": [
    "let numTotalImages = [641, 699, 633, 799, 898]\n",
    "let numTrainImages = [512, 559, 506, 639, 718]  // Number of Train Images = 0.8 * Number of Total Images.\n",
    "var trainList = Python.list()\n",
    "var testList = Python.list()\n",
    "var i = 0, numImagesDone = 0\n",
    "\n",
    "for path in totalImages {\n",
    "    if numImagesDone == numTotalImages[i] {\n",
    "        i += 1\n",
    "        numImagesDone = 0\n",
    "    }\n",
    "    if numImagesDone >= numTrainImages[i] {\n",
    "        testList.append(path)\n",
    "        numImagesDone += 1\n",
    "    } else {\n",
    "        trainList.append(path)\n",
    "        numImagesDone += 1\n",
    "    }\n",
    "}\n",
    "\n",
    "for i in 0..<5 {\n",
    "    np.random.shuffle(trainList)\n",
    "    np.random.shuffle(testList)\n",
    "}\n",
    "\n",
    "print(\"Total Images \\(totalImages.count)\")\n",
    "print(\"Train Images \\(trainList.count)\")\n",
    "print(\"Test Images \\(testList.count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RW_oP9vd83AT"
   },
   "source": [
    "### Visualizing Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoeLuQjY83nZ"
   },
   "source": [
    "We can visualize our training images by creating functions to plot images through their paths or tensors, and then plotting a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZaQBU0R6n-d"
   },
   "outputs": [],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "\n",
    "func plotImages(_ image: Tensor<Float>) {\n",
    "    let numpyImage = image.makeNumpyArray().reshape(150, 150, 3)\n",
    "    plt.imshow(numpyImage)\n",
    "    plt.show()\n",
    "}\n",
    "\n",
    "func plotImages(from path: String) {\n",
    "    let img = pil.Image.open(path)\n",
    "    let image = np.array(img) * (1.0 / 255)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zazRWHDLne_x"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FczZhOBEnhQA"
   },
   "source": [
    "Overfitting often occurs when we have a small number of training examples. One way to fix this problem is to augment our dataset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples through random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This exposes the model to more aspects of the data, allowing it to generalize better.\n",
    "\n",
    "In Swift for TensorFlow we can implement this using the different Python libraries through Python interoperability. WWe can simply apply different transformations we would want to our dataset images and they will be applied during our training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "On5jRhcfnisD"
   },
   "source": [
    "We perform the following image augmentation techniques randomly on an image:\n",
    "\n",
    "* Rotating the image\n",
    "* Transposing\n",
    "* Flipping the image horizontally\n",
    "* Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9IsIJl5nk3L"
   },
   "outputs": [],
   "source": [
    "func augmentedImage(path: String) -> Tensor<Float> {\n",
    "    \n",
    "    var img = pil.Image.open(path)\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.rotate(45) // Rotate 45 degrees.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.transpose(pil.Image.TRANSPOSE) // Transpose.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.transpose(pil.Image.FLIP_LEFT_RIGHT) // Flip.\n",
    "    }\n",
    "    \n",
    "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        image = sk.util.random_noise(image) // Add noise.\n",
    "    }\n",
    "    \n",
    "    image = np.array(image, dtype: np.float32)\n",
    "    \n",
    "    let imageTensor = Tensor<Float>(numpy: image)!\n",
    "\n",
    "    return imageTensor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akDk2rmO70un"
   },
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQ7KrBqH71L0"
   },
   "source": [
    "Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n",
    "\n",
    "1. Read images from the disk.\n",
    "2. Decode the contents of these images into their RGB bytes.\n",
    "3. Convert them into floating point tensors.\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, to better match the range expected by the initial neural network weights.\n",
    "5. Apply or don't apply image augmentation techniques, based on the type of data.\n",
    "\n",
    "We have done this in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRAT9M538M82"
   },
   "source": [
    "The `resizedImage(fromPath:augmented:)` function takes 2 inputs:\n",
    "1. Image path as input.\n",
    "2. Whether or not to apply image augmentations.\n",
    "\n",
    "The `images(fromList:imageCount:augmented:)` function takes 3 inputs :\n",
    "\n",
    "1. List of paths.\n",
    "\n",
    "2. Number of tensors to be produced in the output tensor as input.\n",
    "\n",
    "3. Whether or not to apply image augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DC85ego6kmK"
   },
   "outputs": [],
   "source": [
    "func resizedImage(fromPath: String, augmented: Bool) -> (Tensor<Float>, Int32) {\n",
    "    var img = pil.Image.open(fromPath)\n",
    "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
    "    var imageTensor = Tensor<Float>(numpy: image)!\n",
    "    \n",
    "    if augmented {\n",
    "        imageTensor = augmentedImage(path: fromPath)\n",
    "    }\n",
    "    \n",
    "    imageTensor = imageTensor.expandingShape(at: 0)\n",
    "    imageTensor = Raw.resizeArea(images: imageTensor , size: [150, 150])\n",
    "    \n",
    "    var label: Int32 = 0\n",
    "    \n",
    "    for i in 0 ..< 5 {\n",
    "        if fromPath.contains(classNames[i]) {\n",
    "            label = Int32(i)\n",
    "            break\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return (imageTensor, label)\n",
    "}\n",
    "\n",
    "func images(fromList: PythonObject, imageCount: Int, augmented: Bool) -> (image: Tensor<Float>, label: Tensor<Int32>) {\n",
    "    let batchFiles = fromList[0..<imageCount]\n",
    "    var labels: [Int32] = []\n",
    "    var x: Tensor<Float>\n",
    "    var y: Tensor<Int32>\n",
    "\n",
    "    // Load first image.\n",
    "    let path = String(batchFiles[0]) ?? \"\"\n",
    "    let data = resizedImage(fromPath: path, augmented: augmented)\n",
    "    x = data.0 \n",
    "    labels.append(data.1)\n",
    "\n",
    "    // Load rest of the images.\n",
    "    var numberOfFilesDone = 1\n",
    "    for file in batchFiles[1..<imageCount] {\n",
    "        let path = String(file) ?? \"\"\n",
    "        let data = resizedImage(fromPath: path, augmented: augmented)\n",
    "        let tensor = data.0\n",
    "        labels.append(data.1)\n",
    "        x = Tensor(concatenating: [x, tensor], alongAxis: 0)\n",
    "    }\n",
    "    y = Tensor<Int32>(labels)\n",
    "    return (x, y)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7t-Xyds8dOm"
   },
   "source": [
    "After defining our generators for images and labels, we will load those images and labels in tensor arrays, thereby creating our `testTensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "w9T1CsET6mVn",
    "outputId": "b4550c41-0efe-4ad5-f109-ac66ca02151f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[736, 150, 150, 3]\r\n",
      "[736]\r\n"
     ]
    }
   ],
   "source": [
    "let testTensors = images(fromList: testList, imageCount: testList.count, augmented: false)\n",
    "let testImageTensors = testTensors.0\n",
    "let testLabelTensors = testTensors.1\n",
    "print(testImageTensors.shape)\n",
    "print(testLabelTensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyb5bsh_9Idt"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk5ikBiM9JA8"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "In the cell below, create a convolutional neural network that consists of 3 convolution blocks. Each convolutional block contains a `Conv2D` layer followed by a max pool layer. The first convolutional block should have 16 filters, the second one should have 32 filters, and the third one should have 64 filters. All convolutional filters should be 3 x 3. All max pool layers should have a `poolSize` of `(2, 2)`.\n",
    "\n",
    "After the 3 convolutional blocks you should have a flatten layer followed by a fully connected layer with 512 units. The CNN should output class probabilities based on 5 classes which is done by the **softmax** activation function. All other layers should use a **relu** activation function. You should also add Dropout layers with a probability of 20%,  where appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPf9jf2p6rE-"
   },
   "outputs": [],
   "source": [
    "struct Classifier: Layer {\n",
    "    typealias Input = Tensor<Float>\n",
    "    typealias Output = Tensor<Float>\n",
    "\n",
    "    var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 16), activation: relu)\n",
    "    var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1b = Conv2D<Float>(filterShape: (3, 3, 16, 32), activation: relu)\n",
    "    var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1c = Conv2D<Float>(filterShape: (3, 3, 32, 64), activation: relu)\n",
    "    var pool3 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var flatten = Flatten<Float>()\n",
    "    var dropout1a = Dropout<Float>(probability: 0.2)\n",
    "    var layer1a = Dense<Float>(inputSize: 18496, outputSize: 512, activation: relu)\n",
    "    var dropout1b = Dropout<Float>(probability: 0.2)\n",
    "    var layer1b = Dense<Float>(inputSize: 512, outputSize: 5, activation: softmax)\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Input) -> Output {\n",
    "        var convolved1 = input.sequenced(through: conv1a, pool1)\n",
    "        var convolved2 = convolved1.sequenced(through: conv1b, pool2)\n",
    "        var convolved3 = convolved2.sequenced(through: conv1c, pool3)\n",
    "        var dense1 = convolved3.sequenced(through: flatten, dropout1a, layer1a)\n",
    "        var dense2 = dense1.sequenced(through: dropout1b, layer1b)\n",
    "        return dense2\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_3UQ6ef9N5b"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "As usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `softmaxCrossEntropy` as the loss function. We would also like to look at the training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "MSNPc99r6s08",
    "outputId": "9aaa1f8c-f3b8-42b2-8f18-9b91d7765f4a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚ñø [1, 5]\n",
       "  ‚ñø dimensions : 2 elements\n",
       "    - 0 : 1\n",
       "    - 1 : 5\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let tensor = Tensor<Float>(zeros:[1, 150, 150, 3])\n",
    "var model = Classifier()\n",
    "var optimizer = Adam(for: model, learningRate: 0.001)\n",
    "model(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZ1o31qE6uGz"
   },
   "outputs": [],
   "source": [
    "let epochCount = 80\n",
    "let batchSize = 100\n",
    "\n",
    "// Extract a batch of size batchSize.\n",
    "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int) -> Tensor<Scalar> {\n",
    "    let start = index * batchSize\n",
    "    return x[start..<start + batchSize]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0YEIbAT-m3E"
   },
   "outputs": [],
   "source": [
    "var trainingAccuracy: [Float] = []\n",
    "var validationAccuracy: [Float] = []\n",
    "var trainingLoss: [Float] = []\n",
    "var validationLoss: [Float] = []\n",
    "var epochsRange: [Int] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJvC4F3O9bTW"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuGBD1uY9bt6"
   },
   "source": [
    "It's time to train our network. \n",
    "\n",
    "We need to apply the random image augmentations every time an image is accessed, so we recreate `trainTensors` in every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "RY0hIJK36vnT",
    "outputId": "1b3c562a-7d16-4ce6-e7ef-87ad3693542d"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "error: <Cell 17>:36:33: error: value of type 'Classifier' has no member 'allDifferentiableVariables'\n        optimizer.update(&model.allDifferentiableVariables, along: ùõÅmodel)\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Beginning training...\")\n",
    "\n",
    "struct Statistics {\n",
    "    var correctGuessCount: Int = 0\n",
    "    var totalGuessCount: Int = 0\n",
    "    var totalLoss: Float = 0\n",
    "}\n",
    "\n",
    "// The training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    epochsRange.append(epoch)\n",
    "    var trainStats = Statistics()\n",
    "    var testStats = Statistics()\n",
    "    print(\"Creating Training Dataset for Epoch \\(epoch)\")\n",
    "    let trainTensors = images(fromList: trainList, imageCount: trainList.count, augmented: true)\n",
    "    let trainImageTensors = trainTensors.0\n",
    "    let trainLabelTensors = trainTensors.1\n",
    "    print(\"Dataset Creation Completed\")\n",
    "    \n",
    "    Context.local.learningPhase = .training\n",
    "    for i in 0..<Int(trainList.count) / batchSize {\n",
    "        let x = minibatch(in: trainImageTensors, at: i)\n",
    "        let y = minibatch(in: trainLabelTensors, at: i)\n",
    "        // Compute the gradient with respect to the model.\n",
    "        let ùõÅmodel = model.gradient { model -> Tensor<Float> in\n",
    "            let ≈∑ = model(x)\n",
    "            let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== y\n",
    "            trainStats.correctGuessCount += Int(\n",
    "              Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            trainStats.totalGuessCount += batchSize\n",
    "            let loss = softmaxCrossEntropy(logits: ≈∑, labels: y)\n",
    "            trainStats.totalLoss += loss.scalarized()\n",
    "            return loss\n",
    "        }\n",
    "        // Update the model's differentiable variables along the gradient vector.\n",
    "        optimizer.update(&model, along: ùõÅmodel)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    for i in 0..<Int(testList.count) / batchSize {\n",
    "        let x = minibatch(in: testImageTensors, at: i)\n",
    "        let y = minibatch(in: testLabelTensors, at: i)\n",
    "        // Compute loss on test set.\n",
    "        let ≈∑ = model(x)\n",
    "        let correctPredictions = ≈∑.argmax(squeezingAxis: 1) .== y\n",
    "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        testStats.totalGuessCount += batchSize\n",
    "        let loss = softmaxCrossEntropy(logits: ≈∑, labels: y)\n",
    "        testStats.totalLoss += loss.scalarized()\n",
    "    }\n",
    "    \n",
    "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
    "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
    "    \n",
    "    trainingAccuracy.append(trainAccuracy)\n",
    "    validationAccuracy.append(testAccuracy)\n",
    "    trainingLoss.append(trainStats.totalLoss)\n",
    "    validationLoss.append(testStats.totalLoss)\n",
    "    \n",
    "    print(\"\"\"\n",
    "          [Epoch \\(epoch)] \\\n",
    "          Training Loss: \\(trainStats.totalLoss), \\\n",
    "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\ \n",
    "          (\\(trainAccuracy)), \\\n",
    "          Test Loss: \\(testStats.totalLoss), \\\n",
    "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
    "          (\\(testAccuracy))\n",
    "          \"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRWzpR3q9ho6"
   },
   "source": [
    "### Visualizing results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zD0-Bvf9iD6"
   },
   "source": [
    "We'll now visualize the results we get after training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "4h42Yr6O_3NR",
    "outputId": "f646d271-216d-4817-cbbf-3b064603f86c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize: [12, 8])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Accuracy(l) vs Validation Accuracy(o)\")\n",
    "plt.plot(epochsRange, trainingAccuracy)\n",
    "plt.plot(epochsRange, validationAccuracy)\n",
    "var loc = \"lower right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Loss(u) vs Validation Loss(p)\")\n",
    "plt.plot(epochsRange, trainingLoss)\n",
    "plt.plot(epochsRange, validationLoss)\n",
    "loc = \"upper right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGE3VS9VfcaA"
   },
   "source": [
    "# TODO: Experiment with Different Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OA8_Egr6faNB"
   },
   "source": [
    "So far you've created a CNN with 3 convolutional layers and followed by a fully connected layer with 512 units. In the cells below create a new CNN with a different architecture. Feel free to experiement by changing as many parameters as you like. For example, you can add more convolutional layers, or more fully connected layers. You can also experiement with different filter sizes in your convolutional layers, different number of units in your fully connected layers, different dropout rates, etc... You can also experiment by performing image aumentation with more image transformations that we have seen so far. For example, you can add shear transformations, or you can vary the brightness of the images, etc... Experiment as much as you can and compare the accuracy of your various models. Which parameters give you the best result?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF Tutorial 8",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
