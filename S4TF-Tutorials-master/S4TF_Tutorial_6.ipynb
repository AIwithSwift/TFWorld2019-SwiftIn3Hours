{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArYw4ah2WxvI"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors. [Licensed under the Apache License, Version 2.0](#scrollTo=y_UVSRtBBsJk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bpE2F8WvXHHR"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "// https://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A6S7MO1QXaVF"
   },
   "source": [
    "# Dogs vs Cats Image Classification With Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI_zO-WyXbHT"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/148B0g-zaefmDTWxbEk1OiKGCEPojWwgz\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"Link to be updated\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub link to be updated accordingly</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gMKDv9AXtw4"
   },
   "source": [
    "\n",
    "\n",
    "In this tutorial, we will discuss how to classify images into pictures of cats or pictures of dogs. We'll build an image classifier using `Layer` and load data by creating training and validation tensors of images as well as their corresponding labels.\n",
    "\n",
    "## Specific concepts that will be covered:\n",
    "In the process, we will build practical experience and develop intuition around the following concepts:\n",
    "\n",
    "* Building _data input pipelines_  — How can we efficiently work with data on disk to interface with our model? \n",
    "* _Overfitting_ - what is it, how to identify it?\n",
    "* _Data Augmentation_ and _Dropout_ -  Key techniques to fight overfitting in computer vision tasks that we will incorporate into our data pipeline and image classifier model. \n",
    "\n",
    "## We will follow the general machine learning workflow:\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline \n",
    "3. Build our model\n",
    "4. Train our model\n",
    "5. Test our model\n",
    "6. Improve our model/Repeat the process\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "**Before you begin**\n",
    "\n",
    "Before running the code in this notebook, reset the runtime by going to **Runtime -> Reset all runtimes** in the menu above. If you have been working through several notebooks, this will help you avoid reaching Colab's memory limits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3feKokVXX72h"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ELd6snqWX8PB"
   },
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "*   glob — to read files and directory structure.\n",
    "*   numpy — for some matrix math outside of TensorFlow.\n",
    "*   matplotlib.pyplot — to plot the graph and display images in our training and validation data.\n",
    "*  PIL — to view images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaGgOzPQbGj3"
   },
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import Foundation\n",
    "import Python\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "let np = Python.import(\"numpy\")  // Make numpy available using np.\n",
    "let subprocess = Python.import(\"subprocess\")\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let os = Python.import(\"os\")\n",
    "let glob = Python.import(\"glob\")\n",
    "let pil = Python.import(\"PIL\")\n",
    "let pilImageOps = Python.import(\"PIL.ImageOps\")\n",
    "let random = Python.import(\"random\")\n",
    "let sk = Python.import(\"skimage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VEIK0Qr6YpOw"
   },
   "source": [
    "To build our image classifier, we begin by downloading the dataset. The dataset we are using is a filtered version of the <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs. Cats</a> dataset from Kaggle (ultimately, this dataset is provided by Microsoft Research).\n",
    "\n",
    "In this Colab, we will make use of the `glob` and  `subprocess` module which will read data from disk. We therefore need to directly download *Dogs vs. Cats* from a URL and unzip it to the Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lf_vvLoESGWf"
   },
   "outputs": [],
   "source": [
    "public extension String {\n",
    "    @discardableResult\n",
    "    func shell(_ args: String...) -> String {\n",
    "        let (task, pipe) = (Process(), Pipe())\n",
    "        task.executableURL = URL(fileURLWithPath: self)\n",
    "        (task.arguments, task.standardOutput) = (args, pipe)\n",
    "        do    { try task.run() }\n",
    "        catch { print(\"Unexpected error: \\(error).\") }\n",
    "\n",
    "        let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
    "        return String(data: data, encoding: String.Encoding.utf8) ?? \"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "L7SwG2Ny9JHd",
    "outputId": "4b96310c-4188-4d0a-df8b-01eeacabe279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 291M\r\n",
      "-rw-r--r-- 1 root root 166K Aug 25 12:00 Autoencoder.ipynb\r\n",
      "-rw-r--r-- 1 root root 3.1K Oct 19 09:17 EnableIPythonDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 6.8K Oct 19 09:17 EnableJupyterDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 313K Aug 25 12:00 GAN(Generative Adversarial Network).ipynb\r\n",
      "-rw-r--r-- 1 root root 4.6K Oct 19 09:17 KernelCommunicator.swift\r\n",
      "-rw-r--r-- 1 root root  354 Aug 25 12:00 README.md\r\n",
      "-rw-r--r-- 1 root root  18K Aug 25 12:00 S4TF_Tutorial_1.ipynb\r\n",
      "-rw-r--r-- 1 root root  67K Aug 25 12:00 S4TF_Tutorial_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 577K Aug 25 12:00 S4TF_Tutorial_3.ipynb\r\n",
      "-rw-r--r-- 1 root root 572K Aug 25 12:00 S4TF_Tutorial_4.ipynb\r\n",
      "-rw-r--r-- 1 root root  29K Oct 23 04:03 S4TF_Tutorial_5.ipynb\r\n",
      "-rw-r--r-- 1 root root  32K Oct 23 04:08 S4TF_Tutorial_6.ipynb\r\n",
      "-rw-r--r-- 1 root root  27K Aug 25 12:00 S4TF_Tutorial_7.ipynb\r\n",
      "-rw-r--r-- 1 root root  34K Oct 23 03:41 S4TF_Tutorial_8.ipynb\r\n",
      "drwxr-x--- 5 root root  160 Sep 23  2016 cats_and_dogs_filtered\r\n",
      "-rw-r--r-- 1 root root  65M Aug 25 12:00 cats_and_dogs_filtered.tar.gz\r\n",
      "drwxr-x--- 8 root root  256 Feb 10  2016 flower_photos\r\n",
      "-rw-r--r-- 1 root root 219M Oct 23 03:25 flower_photos.tgz\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "print(\"/bin/ls\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZT6cUMweBCr"
   },
   "source": [
    "We'll now download and unzip the dataset using the `subprocess` library via Python interoperability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "TpyLNoo3RDIQ",
    "outputId": "9a3e2e1b-cb03-4ff5-d1c5-6f8065406bcd"
   },
   "outputs": [],
   "source": [
    "//let command = \"wget -nv -O- https://github.com/Ayush517/S4TF-Tutorials/raw/master/cats_and_dogs_filtered.tar.gz | tar xzf - -C .\"\n",
    "//subprocess.call(command, shell: true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM2tdEkVZGux"
   },
   "source": [
    "The dataset we have downloaded has the following directory structure:\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>\n",
    "\n",
    "We can list the directories with the following terminal command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tvl9Lnce8H_2",
    "outputId": "768257a1-820d-4b3a-d1a6-807001ee0be3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 291M\r\n",
      "-rw-r--r-- 1 root root 166K Aug 25 12:00 Autoencoder.ipynb\r\n",
      "-rw-r--r-- 1 root root 3.1K Oct 19 09:17 EnableIPythonDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 6.8K Oct 19 09:17 EnableJupyterDisplay.swift\r\n",
      "-rw-r--r-- 1 root root 313K Aug 25 12:00 GAN(Generative Adversarial Network).ipynb\r\n",
      "-rw-r--r-- 1 root root 4.6K Oct 19 09:17 KernelCommunicator.swift\r\n",
      "-rw-r--r-- 1 root root  354 Aug 25 12:00 README.md\r\n",
      "-rw-r--r-- 1 root root  18K Aug 25 12:00 S4TF_Tutorial_1.ipynb\r\n",
      "-rw-r--r-- 1 root root  67K Aug 25 12:00 S4TF_Tutorial_2.ipynb\r\n",
      "-rw-r--r-- 1 root root 577K Aug 25 12:00 S4TF_Tutorial_3.ipynb\r\n",
      "-rw-r--r-- 1 root root 572K Aug 25 12:00 S4TF_Tutorial_4.ipynb\r\n",
      "-rw-r--r-- 1 root root  29K Oct 23 04:03 S4TF_Tutorial_5.ipynb\r\n",
      "-rw-r--r-- 1 root root  32K Oct 23 04:08 S4TF_Tutorial_6.ipynb\r\n",
      "-rw-r--r-- 1 root root  27K Aug 25 12:00 S4TF_Tutorial_7.ipynb\r\n",
      "-rw-r--r-- 1 root root  34K Oct 23 03:41 S4TF_Tutorial_8.ipynb\r\n",
      "drwxr-x--- 5 root root  160 Sep 23  2016 cats_and_dogs_filtered\r\n",
      "-rw-r--r-- 1 root root  65M Aug 25 12:00 cats_and_dogs_filtered.tar.gz\r\n",
      "drwxr-x--- 8 root root  256 Feb 10  2016 flower_photos\r\n",
      "-rw-r--r-- 1 root root 219M Oct 23 03:25 flower_photos.tgz\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "print(\"/bin/ls/\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yIEL_bnxZN6X"
   },
   "source": [
    "### Understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dqxHwJADZKVw"
   },
   "source": [
    "We'll now assign variables with the proper file path for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XXJjUDBOTNf4"
   },
   "outputs": [],
   "source": [
    "let catTrainList = glob.glob(\"cats_and_dogs_filtered/train/cats/*.jpg\")\n",
    "let dogTrainList = glob.glob(\"cats_and_dogs_filtered/train/dogs/*.jpg\")\n",
    "let trainList = glob.glob(\"cats_and_dogs_filtered/train/**/*.jpg\")\n",
    "\n",
    "let catTestList  = glob.glob(\"cats_and_dogs_filtered/validation/cats/*.jpg\")\n",
    "let dogTestList  = glob.glob(\"cats_and_dogs_filtered/validation/dogs/*.jpg\")\n",
    "let testList  = glob.glob(\"cats_and_dogs_filtered/validation/**/*.jpg\")\n",
    "\n",
    "for i in 0 ..< 5 {\n",
    "    np.random.shuffle(trainList)\n",
    "    np.random.shuffle(testList)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0v-OItU3ZOOO"
   },
   "source": [
    "Let's look at how many cats and dogs images we have in our training and validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "9pZdnDMKiybF",
    "outputId": "467a97a5-3ffe-44b5-f65d-4ed3cb588898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\r\n",
      "total training dog images: 1000\r\n",
      "total validation cat images: 500\r\n",
      "total validation dog images: 500\r\n",
      "--\r\n",
      "Total training images: 2000\r\n",
      "Total validation images: 1000\r\n",
      "<class 'list'>\r\n"
     ]
    }
   ],
   "source": [
    "print(\"total training cat images: \\(catTrainList.count)\")\n",
    "print(\"total training dog images: \\(dogTrainList.count)\")\n",
    "\n",
    "print(\"total validation cat images: \\(catTestList.count)\")\n",
    "print(\"total validation dog images: \\(dogTestList.count)\")\n",
    "print(\"--\")\n",
    "print(\"Total training images: \\(trainList.count)\")\n",
    "print(\"Total validation images: \\(testList.count)\")\n",
    "\n",
    "print(Python.type(trainList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B1RxO8dzdF2g"
   },
   "source": [
    "### Visualizing Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFz4nx1LdGTZ"
   },
   "source": [
    "We can visualize our training images by creating functions to plot images through their paths or tensors, and then plotting a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCKdKItfmlep"
   },
   "outputs": [],
   "source": [
    "func plotImages(_ image: Tensor<Float>) {\n",
    "    let numpyImage = image.reshaped(to: [150, 150, 3]).makeNumpyArray()\n",
    "    plt.imshow(numpyImage)\n",
    "    plt.show()\n",
    "}\n",
    "\n",
    "func plotImages(fromPath path: String) {\n",
    "    let img = pil.Image.open(path)\n",
    "    let image = np.array(img) * (1.0 / 255)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZRtJODkfxgf"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpIp5hzAfx9P"
   },
   "source": [
    "Overfitting often occurs when we have a small number of training examples. One way to fix this problem is to augment our dataset so that it has sufficient number and variety of training examples. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples through random transformations that yield believable-looking images. The goal is that at training time, your model will never see the exact same picture twice. This exposes the model to more aspects of the data, allowing it to generalize better.\n",
    "\n",
    "In Swift for TensorFlow we can implement this using the different Python libraries through Python interoperability. We can simply apply different transformations we would want to our dataset images and they will be applied during our training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnMOZA_BgREI"
   },
   "source": [
    "We perform the following image augmentation techniques randomly on an image:\n",
    "\n",
    "* Rotating the image\n",
    "* Transposing\n",
    "* Cropping\n",
    "* Flipping the image horizontally\n",
    "* Adding border to image\n",
    "* Adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QE-K4a2Ql8tx"
   },
   "outputs": [],
   "source": [
    "func augmentedImage(path: String) -> Tensor<Float> {\n",
    "    \n",
    "    var img = pil.Image.open(path)\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.rotate(45) // Rotate 45 degrees.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.transpose(pil.Image.TRANSPOSE) // Transpose.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        let h = Float(img.size[0])! / 4\n",
    "        let w = Float(img.size[1])! / 4\n",
    "        let cropBorder = Int(Python.min(h, w))\n",
    "        img = pilImageOps.crop(img,  cropBorder) // Crop by half of shorter sides.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        img = img.transpose(pil.Image.FLIP_LEFT_RIGHT) // Flip.\n",
    "    }\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        let h = Float(img.size[0])! / 10\n",
    "        let w = Float(img.size[1])! / 10\n",
    "        let borderSize = Int(Python.min(h, w))\n",
    "        img = pilImageOps.expand(img, borderSize) // Add border.\n",
    "    }\n",
    "    \n",
    "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
    "    \n",
    "    if random.random() < 0.5 {\n",
    "        image = sk.util.random_noise(image) // Add noise.\n",
    "    }\n",
    "    \n",
    "    image = np.array(image, dtype: np.float32)\n",
    "    \n",
    "    let imageTensor = Tensor<Float>(numpy: image)!\n",
    "\n",
    "    return imageTensor\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vl6vw_AcZd54"
   },
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQ3OILUgZeqb"
   },
   "source": [
    "Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n",
    "\n",
    "1. Read images from the disk.\n",
    "2. Decode the contents of these images into their RGB bytes.\n",
    "3. Convert them into floating point tensors.\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, to better match the range expected by the initial neural network weights.\n",
    "5. Apply or don't apply image augmentation techniques, based on the type of data.\n",
    "\n",
    "We have done this in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FyESvV0ZjhJ"
   },
   "source": [
    "The `resizedImage(fromPath:augmented:)` function takes 2 inputs:\n",
    "1. Image path as input.\n",
    "2. Whether or not to apply image augmentations.\n",
    "\n",
    "The `images(fromList:imageCount:augmented:)` function takes 3 inputs :\n",
    "\n",
    "1. List of paths.\n",
    "\n",
    "2. Number of tensors to be produced in the output tensor as input.\n",
    "\n",
    "3. Whether or not to apply image augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JihjHwPi2Ch"
   },
   "outputs": [],
   "source": [
    "func resizedImage(fromPath: String, augmented: Bool) -> (Tensor<Float>, Int32) {\n",
    "    var img = pil.Image.open(fromPath)\n",
    "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
    "    var imageTensor = Tensor<Float>(numpy: image)!\n",
    "    \n",
    "    if augmented {\n",
    "        imageTensor = augmentedImage(path: fromPath)\n",
    "    }\n",
    "    \n",
    "    imageTensor = imageTensor.expandingShape(at: 0)\n",
    "    imageTensor = Raw.resizeArea(images: imageTensor , size: [150, 150])\n",
    "    \n",
    "    let label: Int32 = fromPath.contains(\"dog.\") ? 0 : 1\n",
    "    \n",
    "    return (imageTensor, label)\n",
    "}\n",
    "\n",
    "func images(fromList: PythonObject, imageCount: Int, augmented: Bool) -> (image: Tensor<Float>, label: Tensor<Int32>) {\n",
    "    let batchFiles = fromList[0..<imageCount]\n",
    "    var labels: [Int32] = []\n",
    "    var x: Tensor<Float>\n",
    "    var y: Tensor<Int32>\n",
    "\n",
    "    // Load first image.\n",
    "    let path = String(batchFiles[0]) ?? \"\"\n",
    "    let data = resizedImage(fromPath: path, augmented: augmented)\n",
    "    x = data.0 \n",
    "    labels.append(data.1)\n",
    "\n",
    "    // Load rest of the images.\n",
    "    var numberOfFilesDone = 1\n",
    "    for file in batchFiles[1..<imageCount] {\n",
    "        let path = String(file) ?? \"\"\n",
    "        let data = resizedImage(fromPath: path, augmented: augmented)\n",
    "        let tensor = data.0\n",
    "        labels.append(data.1)\n",
    "        x = Tensor(concatenating: [x, tensor], alongAxis: 0)\n",
    "    }\n",
    "    y = Tensor<Int32>(labels)\n",
    "    return (x, y)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7m427NXlc7Xw"
   },
   "source": [
    "After defining our generators for images and labels, we will load those images and labels in tensor arrays, thereby creating our `testTensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Xd8WDjGSBZYb",
    "outputId": "34c04a8b-1a0e-487c-f630-51a3a42ff805"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 150, 150, 3]\r\n",
      "[1000]\r\n"
     ]
    }
   ],
   "source": [
    "let testTensors = images(fromList: testList, imageCount: testList.count, augmented: false)\n",
    "let testImageTensors = testTensors.0\n",
    "let testLabelTensors = testTensors.1\n",
    "print(testImageTensors.shape)\n",
    "print(testLabelTensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxjqzqP3doZn"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ye4j5sK9douT"
   },
   "source": [
    "The model consists of four convolution blocks with a max pool layer in each of them.\n",
    "\n",
    "Before the final Dense layers, we're also applying a Dropout probability of 0.5. This mean that 50% of the values coming into the Dropout layer will be set to zero. This helps to prevent overfitting.\n",
    "\n",
    "Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes — dogs and cats — using `softmax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QmaeXuZQUx2k"
   },
   "outputs": [],
   "source": [
    "struct Classifier: Layer {\n",
    "    typealias Input = Tensor<Float>\n",
    "    typealias Output = Tensor<Float>\n",
    "\n",
    "    var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), activation: relu)\n",
    "    var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 64), activation: relu)\n",
    "    var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1c = Conv2D<Float>(filterShape: (3, 3, 64, 128), activation: relu)\n",
    "    var pool3 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1d = Conv2D<Float>(filterShape: (3, 3, 128, 128), activation: relu)\n",
    "    var pool4 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var dropout1a = Dropout<Float>(probability: 0.5)\n",
    "    var flatten = Flatten<Float>()\n",
    "    var layer1a = Dense<Float>(inputSize: 6272, outputSize: 512, activation: relu)\n",
    "    var layer1b = Dense<Float>(inputSize: 512, outputSize: 2, activation: softmax)\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Input) -> Output {\n",
    "        var convolved1 = input.sequenced(through: conv1a, pool1)\n",
    "        var convolved2 = convolved1.sequenced(through: conv1b, pool2)\n",
    "        var convolved3 = convolved2.sequenced(through: conv1c, pool3)\n",
    "        var convolved4 = convolved3.sequenced(through: conv1d, pool4)\n",
    "        return convolved4.sequenced(through: dropout1a, flatten, layer1a, layer1b)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mE4Fv2cwdsWz"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "As usual, we will use the `adam` optimizer. Since we output a softmax categorization, we'll use `softmaxCrossEntropy` as the loss function. We would also like to look at the training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "nsPxQTvwYmy8",
    "outputId": "4aed1df7-2260-476d-d894-9c23fbf4899d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ [1, 2]\n",
       "  ▿ dimensions : 2 elements\n",
       "    - 0 : 1\n",
       "    - 1 : 2\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let tensor = Tensor<Float>(zeros: [1, 150, 150, 3])\n",
    "var classifier = Classifier()\n",
    "var optimizer = Adam(for: classifier)\n",
    "classifier(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fikBuWi3_a9z"
   },
   "outputs": [],
   "source": [
    "let epochCount = 100\n",
    "let batchSize = 100\n",
    "\n",
    "// Extract a batch of size batchSize.\n",
    "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int) -> Tensor<Scalar> {\n",
    "    let start = index * batchSize\n",
    "    return x[start..<start + batchSize]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6oZ-9RKjGM2"
   },
   "outputs": [],
   "source": [
    "var trainingAccuracy: [Float] = []\n",
    "var validationAccuracy: [Float] = []\n",
    "var trainingLoss: [Float] = []\n",
    "var validationLoss: [Float] = []\n",
    "var epochsRange: [Int] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fq7RgKWbeaGZ"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2xgoa_Aeai6"
   },
   "source": [
    "It's time to train our network. \n",
    "\n",
    " We need to apply the random image augmentations every time an image is accessed, so we recreate `trainTensors` in every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lJaSgWCgs90t",
    "outputId": "16001e2c-8cc9-42af-ec44-237a341c9026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Creating Training Dataset for Epoch 1\n",
      "Dataset Creation Completed\n",
      "[Epoch 1] Training Loss: 13.946455, Training Accuracy: 1002/2000 (0.501), Test Loss: 6.834241, Test Accuracy: 513/1000 (0.513)\n",
      "Creating Training Dataset for Epoch 2\n",
      "Dataset Creation Completed\n",
      "[Epoch 2] Training Loss: 13.770681, Training Accuracy: 1093/2000 (0.5465), Test Loss: 6.715851, Test Accuracy: 638/1000 (0.638)\n",
      "Creating Training Dataset for Epoch 3\n",
      "Dataset Creation Completed\n",
      "[Epoch 3] Training Loss: 13.34347, Training Accuracy: 1208/2000 (0.604), Test Loss: 7.0913205, Test Accuracy: 516/1000 (0.516)\n",
      "Creating Training Dataset for Epoch 4\n",
      "Dataset Creation Completed\n",
      "[Epoch 4] Training Loss: 13.070955, Training Accuracy: 1235/2000 (0.6175), Test Loss: 6.136123, Test Accuracy: 687/1000 (0.687)\n",
      "Creating Training Dataset for Epoch 5\n",
      "Dataset Creation Completed\n",
      "[Epoch 5] Training Loss: 12.935558, Training Accuracy: 1247/2000 (0.6235), Test Loss: 6.27857, Test Accuracy: 656/1000 (0.656)\n",
      "Creating Training Dataset for Epoch 6\n",
      "Dataset Creation Completed\n",
      "[Epoch 6] Training Loss: 12.42833, Training Accuracy: 1347/2000 (0.6735), Test Loss: 6.4868135, Test Accuracy: 610/1000 (0.61)\n",
      "Creating Training Dataset for Epoch 7\n",
      "Dataset Creation Completed\n",
      "[Epoch 7] Training Loss: 12.572023, Training Accuracy: 1317/2000 (0.6585), Test Loss: 6.0222187, Test Accuracy: 698/1000 (0.698)\n",
      "Creating Training Dataset for Epoch 8\n",
      "Dataset Creation Completed\n",
      "[Epoch 8] Training Loss: 12.579029, Training Accuracy: 1301/2000 (0.6505), Test Loss: 6.3710585, Test Accuracy: 631/1000 (0.631)\n",
      "Creating Training Dataset for Epoch 9\n",
      "Dataset Creation Completed\n",
      "[Epoch 9] Training Loss: 12.448433, Training Accuracy: 1333/2000 (0.6665), Test Loss: 6.3992724, Test Accuracy: 645/1000 (0.645)\n",
      "Creating Training Dataset for Epoch 10\n",
      "Dataset Creation Completed\n",
      "[Epoch 10] Training Loss: 12.326744, Training Accuracy: 1348/2000 (0.674), Test Loss: 6.655376, Test Accuracy: 601/1000 (0.601)\n",
      "Creating Training Dataset for Epoch 11\n",
      "Dataset Creation Completed\n",
      "[Epoch 11] Training Loss: 12.686592, Training Accuracy: 1280/2000 (0.64), Test Loss: 6.12057, Test Accuracy: 668/1000 (0.668)\n",
      "Creating Training Dataset for Epoch 12\n",
      "Dataset Creation Completed\n",
      "[Epoch 12] Training Loss: 12.282449, Training Accuracy: 1343/2000 (0.6715), Test Loss: 6.2773733, Test Accuracy: 648/1000 (0.648)\n",
      "Creating Training Dataset for Epoch 13\n",
      "Dataset Creation Completed\n",
      "[Epoch 13] Training Loss: 12.1786785, Training Accuracy: 1362/2000 (0.681), Test Loss: 6.0118995, Test Accuracy: 687/1000 (0.687)\n",
      "Creating Training Dataset for Epoch 14\n",
      "Dataset Creation Completed\n",
      "[Epoch 14] Training Loss: 12.096718, Training Accuracy: 1376/2000 (0.688), Test Loss: 6.086546, Test Accuracy: 670/1000 (0.67)\n",
      "Creating Training Dataset for Epoch 15\n",
      "Dataset Creation Completed\n",
      "[Epoch 15] Training Loss: 11.959494, Training Accuracy: 1375/2000 (0.6875), Test Loss: 5.941166, Test Accuracy: 693/1000 (0.693)\n",
      "Creating Training Dataset for Epoch 16\n",
      "Dataset Creation Completed\n",
      "[Epoch 16] Training Loss: 11.867134, Training Accuracy: 1397/2000 (0.6985), Test Loss: 5.868221, Test Accuracy: 706/1000 (0.706)\n",
      "Creating Training Dataset for Epoch 17\n",
      "Dataset Creation Completed\n",
      "[Epoch 17] Training Loss: 11.658398, Training Accuracy: 1432/2000 (0.716), Test Loss: 5.9374046, Test Accuracy: 702/1000 (0.702)\n",
      "Creating Training Dataset for Epoch 18\n",
      "Dataset Creation Completed\n",
      "[Epoch 18] Training Loss: 11.789434, Training Accuracy: 1426/2000 (0.713), Test Loss: 5.877285, Test Accuracy: 707/1000 (0.707)\n",
      "Creating Training Dataset for Epoch 19\n",
      "Dataset Creation Completed\n",
      "[Epoch 19] Training Loss: 11.767937, Training Accuracy: 1410/2000 (0.705), Test Loss: 5.8084736, Test Accuracy: 711/1000 (0.711)\n",
      "Creating Training Dataset for Epoch 20\n",
      "Dataset Creation Completed\n",
      "[Epoch 20] Training Loss: 11.80527, Training Accuracy: 1410/2000 (0.705), Test Loss: 6.002752, Test Accuracy: 696/1000 (0.696)\n",
      "Creating Training Dataset for Epoch 21\n",
      "Dataset Creation Completed\n",
      "[Epoch 21] Training Loss: 12.117684, Training Accuracy: 1388/2000 (0.694), Test Loss: 6.408204, Test Accuracy: 643/1000 (0.643)\n",
      "Creating Training Dataset for Epoch 22\n",
      "Dataset Creation Completed\n",
      "[Epoch 22] Training Loss: 12.227397, Training Accuracy: 1346/2000 (0.673), Test Loss: 6.0828037, Test Accuracy: 679/1000 (0.679)\n",
      "Creating Training Dataset for Epoch 23\n",
      "Dataset Creation Completed\n",
      "[Epoch 23] Training Loss: 11.613655, Training Accuracy: 1438/2000 (0.719), Test Loss: 5.8458095, Test Accuracy: 713/1000 (0.713)\n",
      "Creating Training Dataset for Epoch 24\n",
      "Dataset Creation Completed\n",
      "[Epoch 24] Training Loss: 11.618054, Training Accuracy: 1413/2000 (0.7065), Test Loss: 5.941551, Test Accuracy: 698/1000 (0.698)\n",
      "Creating Training Dataset for Epoch 25\n",
      "Dataset Creation Completed\n",
      "[Epoch 25] Training Loss: 11.8150215, Training Accuracy: 1393/2000 (0.6965), Test Loss: 6.4859686, Test Accuracy: 634/1000 (0.634)\n",
      "Creating Training Dataset for Epoch 26\n",
      "Dataset Creation Completed\n",
      "[Epoch 26] Training Loss: 11.778402, Training Accuracy: 1402/2000 (0.701), Test Loss: 5.7905173, Test Accuracy: 715/1000 (0.715)\n",
      "Creating Training Dataset for Epoch 27\n",
      "Dataset Creation Completed\n",
      "[Epoch 27] Training Loss: 11.389856, Training Accuracy: 1478/2000 (0.739), Test Loss: 6.191954, Test Accuracy: 667/1000 (0.667)\n",
      "Creating Training Dataset for Epoch 28\n",
      "Dataset Creation Completed\n",
      "[Epoch 28] Training Loss: 11.569814, Training Accuracy: 1423/2000 (0.7115), Test Loss: 6.057321, Test Accuracy: 674/1000 (0.674)\n",
      "Creating Training Dataset for Epoch 29\n",
      "Dataset Creation Completed\n",
      "[Epoch 29] Training Loss: 11.546938, Training Accuracy: 1442/2000 (0.721), Test Loss: 5.7263794, Test Accuracy: 731/1000 (0.731)\n",
      "Creating Training Dataset for Epoch 30\n",
      "Dataset Creation Completed\n",
      "[Epoch 30] Training Loss: 11.463304, Training Accuracy: 1442/2000 (0.721), Test Loss: 5.7515035, Test Accuracy: 716/1000 (0.716)\n",
      "Creating Training Dataset for Epoch 31\n",
      "Dataset Creation Completed\n",
      "[Epoch 31] Training Loss: 11.297242, Training Accuracy: 1462/2000 (0.731), Test Loss: 5.7703533, Test Accuracy: 714/1000 (0.714)\n",
      "Creating Training Dataset for Epoch 32\n",
      "Dataset Creation Completed\n",
      "[Epoch 32] Training Loss: 11.581067, Training Accuracy: 1441/2000 (0.7205), Test Loss: 5.66332, Test Accuracy: 738/1000 (0.738)\n",
      "Creating Training Dataset for Epoch 33\n",
      "Dataset Creation Completed\n",
      "[Epoch 33] Training Loss: 11.438463, Training Accuracy: 1454/2000 (0.727), Test Loss: 5.7142634, Test Accuracy: 735/1000 (0.735)\n",
      "Creating Training Dataset for Epoch 34\n",
      "Dataset Creation Completed\n",
      "[Epoch 34] Training Loss: 11.49957, Training Accuracy: 1426/2000 (0.713), Test Loss: 5.7641125, Test Accuracy: 716/1000 (0.716)\n",
      "Creating Training Dataset for Epoch 35\n",
      "Dataset Creation Completed\n",
      "[Epoch 35] Training Loss: 11.356556, Training Accuracy: 1447/2000 (0.7235), Test Loss: 5.7721624, Test Accuracy: 712/1000 (0.712)\n",
      "Creating Training Dataset for Epoch 36\n",
      "Dataset Creation Completed\n",
      "[Epoch 36] Training Loss: 11.33092, Training Accuracy: 1468/2000 (0.734), Test Loss: 5.803649, Test Accuracy: 706/1000 (0.706)\n",
      "Creating Training Dataset for Epoch 37\n",
      "Dataset Creation Completed\n",
      "[Epoch 37] Training Loss: 11.198086, Training Accuracy: 1476/2000 (0.738), Test Loss: 5.6828947, Test Accuracy: 726/1000 (0.726)\n",
      "Creating Training Dataset for Epoch 38\n",
      "Dataset Creation Completed\n",
      "[Epoch 38] Training Loss: 11.12915, Training Accuracy: 1501/2000 (0.7505), Test Loss: 5.675171, Test Accuracy: 729/1000 (0.729)\n",
      "Creating Training Dataset for Epoch 39\n",
      "Dataset Creation Completed\n",
      "[Epoch 39] Training Loss: 11.027215, Training Accuracy: 1492/2000 (0.746), Test Loss: 5.6841345, Test Accuracy: 730/1000 (0.73)\n",
      "Creating Training Dataset for Epoch 40\n",
      "Dataset Creation Completed\n",
      "[Epoch 40] Training Loss: 11.442066, Training Accuracy: 1425/2000 (0.7125), Test Loss: 5.676037, Test Accuracy: 725/1000 (0.725)\n",
      "Creating Training Dataset for Epoch 41\n",
      "Dataset Creation Completed\n",
      "[Epoch 41] Training Loss: 11.039977, Training Accuracy: 1486/2000 (0.743), Test Loss: 5.7457404, Test Accuracy: 721/1000 (0.721)\n",
      "Creating Training Dataset for Epoch 42\n",
      "Dataset Creation Completed\n",
      "[Epoch 42] Training Loss: 11.218602, Training Accuracy: 1478/2000 (0.739), Test Loss: 5.9453945, Test Accuracy: 695/1000 (0.695)\n",
      "Creating Training Dataset for Epoch 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Creation Completed\n",
      "[Epoch 43] Training Loss: 11.323771, Training Accuracy: 1457/2000 (0.7285), Test Loss: 5.8948913, Test Accuracy: 690/1000 (0.69)\n",
      "Creating Training Dataset for Epoch 44\n",
      "Dataset Creation Completed\n",
      "[Epoch 44] Training Loss: 11.317758, Training Accuracy: 1460/2000 (0.73), Test Loss: 5.686451, Test Accuracy: 719/1000 (0.719)\n",
      "Creating Training Dataset for Epoch 45\n",
      "Dataset Creation Completed\n",
      "[Epoch 45] Training Loss: 11.238015, Training Accuracy: 1468/2000 (0.734), Test Loss: 5.886337, Test Accuracy: 695/1000 (0.695)\n",
      "Creating Training Dataset for Epoch 46\n",
      "Dataset Creation Completed\n",
      "[Epoch 46] Training Loss: 11.156042, Training Accuracy: 1483/2000 (0.7415), Test Loss: 5.886538, Test Accuracy: 699/1000 (0.699)\n",
      "Creating Training Dataset for Epoch 47\n",
      "Dataset Creation Completed\n",
      "[Epoch 47] Training Loss: 11.086395, Training Accuracy: 1485/2000 (0.7425), Test Loss: 5.801791, Test Accuracy: 721/1000 (0.721)\n",
      "Creating Training Dataset for Epoch 48\n",
      "Dataset Creation Completed\n",
      "[Epoch 48] Training Loss: 11.340703, Training Accuracy: 1465/2000 (0.7325), Test Loss: 5.867579, Test Accuracy: 701/1000 (0.701)\n",
      "Creating Training Dataset for Epoch 49\n",
      "Dataset Creation Completed\n",
      "[Epoch 49] Training Loss: 11.103367, Training Accuracy: 1498/2000 (0.749), Test Loss: 5.676611, Test Accuracy: 721/1000 (0.721)\n",
      "Creating Training Dataset for Epoch 50\n",
      "Dataset Creation Completed\n",
      "[Epoch 50] Training Loss: 11.037189, Training Accuracy: 1489/2000 (0.7445), Test Loss: 5.7588677, Test Accuracy: 718/1000 (0.718)\n",
      "Creating Training Dataset for Epoch 51\n",
      "Dataset Creation Completed\n",
      "[Epoch 51] Training Loss: 11.091126, Training Accuracy: 1478/2000 (0.739), Test Loss: 5.627808, Test Accuracy: 733/1000 (0.733)\n",
      "Creating Training Dataset for Epoch 52\n",
      "Dataset Creation Completed\n",
      "[Epoch 52] Training Loss: 11.253338, Training Accuracy: 1464/2000 (0.732), Test Loss: 5.6510825, Test Accuracy: 727/1000 (0.727)\n",
      "Creating Training Dataset for Epoch 53\n",
      "Dataset Creation Completed\n",
      "[Epoch 53] Training Loss: 11.181121, Training Accuracy: 1477/2000 (0.7385), Test Loss: 5.6238155, Test Accuracy: 732/1000 (0.732)\n",
      "Creating Training Dataset for Epoch 54\n",
      "Dataset Creation Completed\n",
      "[Epoch 54] Training Loss: 10.939375, Training Accuracy: 1514/2000 (0.757), Test Loss: 5.5121074, Test Accuracy: 750/1000 (0.75)\n",
      "Creating Training Dataset for Epoch 55\n",
      "Dataset Creation Completed\n",
      "[Epoch 55] Training Loss: 11.026463, Training Accuracy: 1505/2000 (0.7525), Test Loss: 5.5725946, Test Accuracy: 737/1000 (0.737)\n",
      "Creating Training Dataset for Epoch 56\n",
      "Dataset Creation Completed\n",
      "[Epoch 56] Training Loss: 11.09828, Training Accuracy: 1485/2000 (0.7425), Test Loss: 5.500243, Test Accuracy: 753/1000 (0.753)\n",
      "Creating Training Dataset for Epoch 57\n",
      "Dataset Creation Completed\n",
      "[Epoch 57] Training Loss: 10.994063, Training Accuracy: 1498/2000 (0.749), Test Loss: 5.5883436, Test Accuracy: 738/1000 (0.738)\n",
      "Creating Training Dataset for Epoch 58\n",
      "Dataset Creation Completed\n",
      "[Epoch 58] Training Loss: 10.777146, Training Accuracy: 1532/2000 (0.766), Test Loss: 5.911215, Test Accuracy: 686/1000 (0.686)\n",
      "Creating Training Dataset for Epoch 59\n",
      "Dataset Creation Completed\n",
      "[Epoch 59] Training Loss: 10.899355, Training Accuracy: 1520/2000 (0.76), Test Loss: 5.593328, Test Accuracy: 736/1000 (0.736)\n",
      "Creating Training Dataset for Epoch 60\n",
      "Dataset Creation Completed\n",
      "[Epoch 60] Training Loss: 10.757809, Training Accuracy: 1526/2000 (0.763), Test Loss: 5.400188, Test Accuracy: 756/1000 (0.756)\n",
      "Creating Training Dataset for Epoch 61\n",
      "Dataset Creation Completed\n",
      "[Epoch 61] Training Loss: 10.670535, Training Accuracy: 1537/2000 (0.7685), Test Loss: 5.5581107, Test Accuracy: 739/1000 (0.739)\n",
      "Creating Training Dataset for Epoch 62\n",
      "Dataset Creation Completed\n",
      "[Epoch 62] Training Loss: 10.889841, Training Accuracy: 1514/2000 (0.757), Test Loss: 5.9179068, Test Accuracy: 696/1000 (0.696)\n",
      "Creating Training Dataset for Epoch 63\n",
      "Dataset Creation Completed\n",
      "[Epoch 63] Training Loss: 10.881156, Training Accuracy: 1510/2000 (0.755), Test Loss: 5.867316, Test Accuracy: 708/1000 (0.708)\n",
      "Creating Training Dataset for Epoch 64\n",
      "Dataset Creation Completed\n",
      "[Epoch 64] Training Loss: 10.998337, Training Accuracy: 1497/2000 (0.7485), Test Loss: 5.838519, Test Accuracy: 701/1000 (0.701)\n",
      "Creating Training Dataset for Epoch 65\n",
      "Dataset Creation Completed\n",
      "[Epoch 65] Training Loss: 11.147721, Training Accuracy: 1504/2000 (0.752), Test Loss: 5.7117186, Test Accuracy: 718/1000 (0.718)\n",
      "Creating Training Dataset for Epoch 66\n",
      "Dataset Creation Completed\n",
      "[Epoch 66] Training Loss: 10.918089, Training Accuracy: 1520/2000 (0.76), Test Loss: 5.371201, Test Accuracy: 763/1000 (0.763)\n",
      "Creating Training Dataset for Epoch 67\n",
      "Dataset Creation Completed\n",
      "[Epoch 67] Training Loss: 10.814222, Training Accuracy: 1520/2000 (0.76), Test Loss: 5.6743574, Test Accuracy: 722/1000 (0.722)\n",
      "Creating Training Dataset for Epoch 68\n",
      "Dataset Creation Completed\n",
      "[Epoch 68] Training Loss: 10.600402, Training Accuracy: 1548/2000 (0.774), Test Loss: 5.7015514, Test Accuracy: 714/1000 (0.714)\n",
      "Creating Training Dataset for Epoch 69\n",
      "Dataset Creation Completed\n",
      "[Epoch 69] Training Loss: 10.748161, Training Accuracy: 1524/2000 (0.762), Test Loss: 5.4188795, Test Accuracy: 752/1000 (0.752)\n",
      "Creating Training Dataset for Epoch 70\n",
      "Dataset Creation Completed\n",
      "[Epoch 70] Training Loss: 10.743478, Training Accuracy: 1521/2000 (0.7605), Test Loss: 5.3802233, Test Accuracy: 757/1000 (0.757)\n",
      "Creating Training Dataset for Epoch 71\n",
      "Dataset Creation Completed\n",
      "[Epoch 71] Training Loss: 10.654458, Training Accuracy: 1537/2000 (0.7685), Test Loss: 5.332396, Test Accuracy: 764/1000 (0.764)\n",
      "Creating Training Dataset for Epoch 72\n",
      "Dataset Creation Completed\n",
      "[Epoch 72] Training Loss: 10.853714, Training Accuracy: 1504/2000 (0.752), Test Loss: 5.268054, Test Accuracy: 782/1000 (0.782)\n",
      "Creating Training Dataset for Epoch 73\n",
      "Dataset Creation Completed\n",
      "[Epoch 73] Training Loss: 10.387667, Training Accuracy: 1555/2000 (0.7775), Test Loss: 5.2788944, Test Accuracy: 779/1000 (0.779)\n",
      "Creating Training Dataset for Epoch 74\n",
      "Dataset Creation Completed\n",
      "[Epoch 74] Training Loss: 10.580682, Training Accuracy: 1557/2000 (0.7785), Test Loss: 5.303532, Test Accuracy: 776/1000 (0.776)\n",
      "Creating Training Dataset for Epoch 75\n",
      "Dataset Creation Completed\n",
      "[Epoch 75] Training Loss: 10.531938, Training Accuracy: 1552/2000 (0.776), Test Loss: 5.4010997, Test Accuracy: 756/1000 (0.756)\n",
      "Creating Training Dataset for Epoch 76\n",
      "Dataset Creation Completed\n",
      "[Epoch 76] Training Loss: 10.448839, Training Accuracy: 1554/2000 (0.777), Test Loss: 5.337316, Test Accuracy: 768/1000 (0.768)\n",
      "Creating Training Dataset for Epoch 77\n",
      "Dataset Creation Completed\n",
      "[Epoch 77] Training Loss: 10.810121, Training Accuracy: 1522/2000 (0.761), Test Loss: 5.4955053, Test Accuracy: 747/1000 (0.747)\n",
      "Creating Training Dataset for Epoch 78\n",
      "Dataset Creation Completed\n",
      "[Epoch 78] Training Loss: 10.882926, Training Accuracy: 1506/2000 (0.753), Test Loss: 5.425091, Test Accuracy: 756/1000 (0.756)\n",
      "Creating Training Dataset for Epoch 79\n",
      "Dataset Creation Completed\n",
      "[Epoch 79] Training Loss: 10.477006, Training Accuracy: 1547/2000 (0.7735), Test Loss: 5.4821844, Test Accuracy: 745/1000 (0.745)\n",
      "Creating Training Dataset for Epoch 80\n",
      "Dataset Creation Completed\n",
      "[Epoch 80] Training Loss: 10.706321, Training Accuracy: 1535/2000 (0.7675), Test Loss: 5.453582, Test Accuracy: 746/1000 (0.746)\n",
      "Creating Training Dataset for Epoch 81\n",
      "Dataset Creation Completed\n",
      "[Epoch 81] Training Loss: 10.652389, Training Accuracy: 1542/2000 (0.771), Test Loss: 5.4285207, Test Accuracy: 752/1000 (0.752)\n",
      "Creating Training Dataset for Epoch 82\n",
      "Dataset Creation Completed\n",
      "[Epoch 82] Training Loss: 10.458154, Training Accuracy: 1557/2000 (0.7785), Test Loss: 5.2063384, Test Accuracy: 784/1000 (0.784)\n",
      "Creating Training Dataset for Epoch 83\n",
      "Dataset Creation Completed\n",
      "[Epoch 83] Training Loss: 10.524572, Training Accuracy: 1557/2000 (0.7785), Test Loss: 5.6098323, Test Accuracy: 737/1000 (0.737)\n",
      "Creating Training Dataset for Epoch 84\n",
      "Dataset Creation Completed\n",
      "[Epoch 84] Training Loss: 10.628524, Training Accuracy: 1545/2000 (0.7725), Test Loss: 5.4943085, Test Accuracy: 748/1000 (0.748)\n",
      "Creating Training Dataset for Epoch 85\n",
      "Dataset Creation Completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 85] Training Loss: 10.2991705, Training Accuracy: 1574/2000 (0.787), Test Loss: 5.355801, Test Accuracy: 771/1000 (0.771)\n",
      "Creating Training Dataset for Epoch 86\n",
      "Dataset Creation Completed\n",
      "[Epoch 86] Training Loss: 10.512774, Training Accuracy: 1560/2000 (0.78), Test Loss: 5.6194916, Test Accuracy: 732/1000 (0.732)\n",
      "Creating Training Dataset for Epoch 87\n",
      "Dataset Creation Completed\n",
      "[Epoch 87] Training Loss: 10.431697, Training Accuracy: 1562/2000 (0.781), Test Loss: 5.4510646, Test Accuracy: 752/1000 (0.752)\n",
      "Creating Training Dataset for Epoch 88\n",
      "Dataset Creation Completed\n",
      "[Epoch 88] Training Loss: 10.607613, Training Accuracy: 1537/2000 (0.7685), Test Loss: 5.504549, Test Accuracy: 744/1000 (0.744)\n",
      "Creating Training Dataset for Epoch 89\n",
      "Dataset Creation Completed\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Current stack trace:",
      "\tframe #27: 0x00007f60ac506825 $__lldb_expr107`main at <Cell 17>:36:19"
     ]
    }
   ],
   "source": [
    "print(\"Beginning training...\")\n",
    "\n",
    "struct Statistics {\n",
    "    var correctGuessCount: Int = 0\n",
    "    var totalGuessCount: Int = 0\n",
    "    var totalLoss: Float = 0\n",
    "}\n",
    "\n",
    "// The training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    epochsRange.append(epoch)\n",
    "    var trainStats = Statistics()\n",
    "    var testStats = Statistics()\n",
    "    print(\"Creating Training Dataset for Epoch \\(epoch)\")\n",
    "    let trainTensors = images(fromList: trainList, imageCount: trainList.count, augmented: true)\n",
    "    let trainImageTensors = trainTensors.0\n",
    "    let trainLabelTensors = trainTensors.1\n",
    "    print(\"Dataset Creation Completed\")\n",
    "    \n",
    "    Context.local.learningPhase = .training\n",
    "    for i in 0..<Int(trainList.count) / batchSize {\n",
    "        let x = minibatch(in: trainImageTensors, at: i)\n",
    "        let y = minibatch(in: trainLabelTensors, at: i)\n",
    "        // Compute the gradient with respect to the model.\n",
    "        let 𝛁model = classifier.gradient { classifier -> Tensor<Float> in\n",
    "            let ŷ = classifier(x)\n",
    "            let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
    "            trainStats.correctGuessCount += Int(\n",
    "              Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            trainStats.totalGuessCount += batchSize\n",
    "            let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
    "            trainStats.totalLoss += loss.scalarized()\n",
    "            return loss\n",
    "        }\n",
    "        // Update the model's differentiable variables along the gradient vector.\n",
    "        optimizer.update(&classifier, along: 𝛁model)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    for i in 0..<Int(testList.count) / batchSize {\n",
    "        let x = minibatch(in: testImageTensors, at: i)\n",
    "        let y = minibatch(in: testLabelTensors, at: i)\n",
    "        // Compute loss on test set.\n",
    "        let ŷ = classifier(x)\n",
    "        let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
    "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        testStats.totalGuessCount += batchSize\n",
    "        let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
    "        testStats.totalLoss += loss.scalarized()\n",
    "    }\n",
    "    \n",
    "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
    "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
    "    \n",
    "    trainingAccuracy.append(trainAccuracy)\n",
    "    validationAccuracy.append(testAccuracy)\n",
    "    trainingLoss.append(trainStats.totalLoss)\n",
    "    validationLoss.append(testStats.totalLoss)\n",
    "    \n",
    "    print(\"\"\"\n",
    "          [Epoch \\(epoch)] \\\n",
    "          Training Loss: \\(trainStats.totalLoss), \\\n",
    "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\ \n",
    "          (\\(trainAccuracy)), \\\n",
    "          Test Loss: \\(testStats.totalLoss), \\\n",
    "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
    "          (\\(testAccuracy))\n",
    "          \"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "8K2cWGKwe5hz"
   },
   "outputs": [],
   "source": [
    "### Visualizing results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-YeHX65e6l0"
   },
   "source": [
    "We'll now visualize the results we get after training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "colab_type": "code",
    "id": "nmqhLD0UjLLo",
    "outputId": "a8782a67-4e25-4fdd-aedf-c1dff3c7edf6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize: [12, 8])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Accuracy(l) vs Validation Accuracy(o)\")\n",
    "plt.plot(epochsRange, trainingAccuracy)\n",
    "plt.plot(epochsRange, validationAccuracy)\n",
    "var loc = \"lower right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Loss(u) vs Validation Loss(p)\")\n",
    "plt.plot(epochsRange, trainingLoss)\n",
    "plt.plot(epochsRange, validationLoss)\n",
    "loc = \"upper right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IV4iitDGbroi"
   },
   "source": [
    "As we can see from the plots, training accuracy and validation accuracy are off by a much smaller margin than what we saw in Tutorial 5 and our model has achieved around **73%** accuracy on the validation set with a training accuracy of **78%** (depending on the number of epochs you trained for).\n",
    "\n",
    "This is a clear indication that we have prevented overfitting by performing image augmentation techniques on our training images."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF Tutorial 6",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
