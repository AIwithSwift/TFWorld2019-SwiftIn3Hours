{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 7 | Making a GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not here to teach the fundamentals of neural networks or ML, but we think GANs are a pretty neat demo. GANs (Generative Adversarial Networks) have two entirely separate networks (models) that work together/compete against each other to generate something.\n",
    "\n",
    "Their overarching goal is to generate new data that is somewhat similar to some of the data they were trained with.\n",
    "\n",
    "IMAGE OF GAN ARCHITECTURE HERE?\n",
    "    \n",
    "Basically, the **generator** generates fake images that are then used by the **discriminator** to see if they're real. Working together, they both get cleverer and cleverer, until the discriminator cannot distinguish the difference between generator-generated images, and the real thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import `Datasets`, so we can use the MNIST data, `Foundation` so we can use the Swift types, `TensorFlow`, so we can use the machine learning bits and pieces, and `ModelSupport`, which helps us work with existing datasets and files. We also include a file `GANSupport.swift` which is a collection of convenience methods and helpers to write/read files, and such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Datasets\n",
    "import Foundation\n",
    "import ModelSupport\n",
    "import TensorFlow\n",
    "%include \"GANSupport.swift\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our parameters are as follows:\n",
    "\n",
    "* `epochCount` is how many epochs it should train for. 10 is a good number to get a reasonable GAN in this case.\n",
    "* `batchSize` is the size of a batch that we're going to ask the MNIST dataset for.\n",
    "* `outputFolder` defines the output folder where we'll be writing things on the file system.\n",
    "* `imageHeight` and `imageWidth`, together with `imageSize` define the output imagesize that the Generator will make, as well as (naturally) the input image size the Discriminator will take.\n",
    "* `latentSize` defines the latent representation size used by the Generator to generate.\n",
    "* `testImageGridSize` defines the size of the grid of images that we'll generate to look at the result of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "let epochCount = 10\n",
    "let batchSize = 32\n",
    "let outputFolder = \"./MNIST_GAN_Output/\"\n",
    "let imageHeight = 28\n",
    "let imageWidth = 28\n",
    "let imageSize = imageHeight * imageWidth\n",
    "let latentSize = 64\n",
    "let testImageGridSize = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Generator` is a `Struct` adhering to the  [`Layer` Protocol](https://www.tensorflow.org/swift/api_docs/Protocols/Layer) (which is part of Swift For TensorFlow's API). The Generator has the following layers:\n",
    "\n",
    "* `dense1`, a `Dense` layer (a [densely-connected layer](https://www.tensorflow.org/swift/api_docs/Structs/Dense)) that takes an `inputSize` of `latentSize` (defined earlier), and an `outputSize` of `latentSize*2`. The `activation` function determines the output shape of each node in the layer. There are many available activations, but [ReLU](https://www.tensorflow.org/swift/api_docs/Functions#leakyrelu_:alpha:) is common for hidden layers.\n",
    "\n",
    "* `dense2` is likewise, but with an `inputSize` of `latentSize*2` (taking the output of the previous layer), and an `outputSize` of `latestSize*4`.\n",
    "\n",
    "* `dense3` is likewise, taking the previous output as input, and outputting it larger.\n",
    "\n",
    "* `dense4` is, again, the same, but has an `outputSize` of `imageSize` instead (our final desired image size). It uses [tanh](https://www.tensorflow.org/swift/api_docs/Functions#tanh_:) as its activation, tanh (hyperbolic tangent) is sigmoidal (s-shaped) and outputs values that range from -1 to 1.\n",
    "\n",
    "* three [`BatchNorm`]() layers, `batchnorm1`, `batchnorm2`, `batchnorm3`, that normalise the activations of the previous layer at each batch by applying transformations that maintain the mean activation close to 0 and the activation standard deviation close to 1. `featureCount` is the number of features.\n",
    "    \n",
    "Finally, we have our `callAsFunction()` method, which sequences through the `Dense` layers, using the `BatchNorm` layers to normalise, before finally returning the output of the fourth and final `Dense` layer.\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Generator: Layer {\n",
    "    var dense1 = Dense<Float>(\n",
    "        inputSize: latentSize, outputSize: latentSize * 2,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense2 = Dense<Float>(\n",
    "        inputSize: latentSize * 2, outputSize: latentSize * 4,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense3 = Dense<Float>(\n",
    "        inputSize: latentSize * 4, outputSize: latentSize * 8,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense4 = Dense<Float>(\n",
    "        inputSize: latentSize * 8, outputSize: imageSize,\n",
    "        activation: tanh)\n",
    "\n",
    "    var batchnorm1 = BatchNorm<Float>(featureCount: latentSize * 2)\n",
    "    var batchnorm2 = BatchNorm<Float>(featureCount: latentSize * 4)\n",
    "    var batchnorm3 = BatchNorm<Float>(featureCount: latentSize * 8)\n",
    "\n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let x1 = batchnorm1(dense1(input))\n",
    "        let x2 = batchnorm2(dense2(x1))\n",
    "        let x3 = batchnorm3(dense3(x2))\n",
    "        return dense4(x3)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `Discriminator` is a `Struct` adhering to the `Layer` Protocol. The `Discriminator` has the following layers:\n",
    "\n",
    "* `dense1`, a `Dense` layer, taking an `inputSize` of `imageSize`, outputting an `outputSize` of 256. It also uses ReLU for activation.\n",
    "\n",
    "* `dense2` and `dense3`, which take an `inputSize` and `outputSize` of 256 and 64, and 64 and 16, respectively, also using ReLU.\n",
    "\n",
    "* `dense4`, which takes the `inputSize` of 16, and has an `outputSize` of 1, and using `identity` as the activation (just linear).\n",
    "\n",
    "Finally, we have our `callAsFunction()` method, which just sequences the input through the four (`Dense`) layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Discriminator: Layer {\n",
    "    var dense1 = Dense<Float>(\n",
    "        inputSize: imageSize, outputSize: 256,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense2 = Dense<Float>(\n",
    "        inputSize: 256, outputSize: 64,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense3 = Dense<Float>(\n",
    "        inputSize: 64, outputSize: 16,\n",
    "        activation: { leakyRelu($0) })\n",
    "\n",
    "    var dense4 = Dense<Float>(\n",
    "        inputSize: 16, outputSize: 1,\n",
    "        activation: identity)\n",
    "\n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        input.sequenced(through: dense1, dense2, dense3, dense4)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `discriminatorLoss()` function, which takes both the real and fake [logits](https://datascience.stackexchange.com/a/31045), and returns the `realLoss` and `fakeLoss`, via the `sigmoidCrossEntropy()` function. That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@differentiable\n",
    "func discriminatorLoss(realLogits: Tensor<Float>, fakeLogits: Tensor<Float>) -> Tensor<Float> {\n",
    "    let realLoss = sigmoidCrossEntropy(\n",
    "        logits: realLogits,\n",
    "        labels: Tensor(ones: realLogits.shape))\n",
    "    let fakeLoss = sigmoidCrossEntropy(\n",
    "        logits: fakeLogits,\n",
    "        labels: Tensor(zeros: fakeLogits.shape))\n",
    "    return realLoss + fakeLoss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `generatorLoss()` function takes the fake logits, and calculates the `sigmoidCrossEntropy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@differentiable\n",
    "func generatorLoss(fakeLogits: Tensor<Float>) -> Tensor<Float> {\n",
    "    sigmoidCrossEntropy(\n",
    "        logits: fakeLogits,\n",
    "        labels: Tensor(ones: fakeLogits.shape))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `sampleVector()` function returns random stuff, that we use for both the Discriminator and Generator later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// Returns `size` samples of noise vector.\n",
    "func sampleVector(size: Int) -> Tensor<Float> {\n",
    "    Tensor(randomNormal: [size, latentSize])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the \"Hello, world!\" of machine learning, MNIST, as our dataset. This comes from some of the helper libraries we've provided for this session (which, in turn, are largely drawn from deep in the bowels of the TensorFlow project):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading resource: train-images-idx3-ubyte\n",
      "Loading local data at: /notebooks/TFWorld_2019_Finished_Examples/train-images-idx3-ubyte\n",
      "Succesfully loaded resource: train-images-idx3-ubyte\n",
      "Loading resource: train-labels-idx1-ubyte\n",
      "Loading local data at: /notebooks/TFWorld_2019_Finished_Examples/train-labels-idx1-ubyte\n",
      "Succesfully loaded resource: train-labels-idx1-ubyte\n",
      "Loading resource: t10k-images-idx3-ubyte\n",
      "Loading local data at: /notebooks/TFWorld_2019_Finished_Examples/t10k-images-idx3-ubyte\n",
      "Succesfully loaded resource: t10k-images-idx3-ubyte\n",
      "Loading resource: t10k-labels-idx1-ubyte\n",
      "Loading local data at: /notebooks/TFWorld_2019_Finished_Examples/t10k-labels-idx1-ubyte\n",
      "Succesfully loaded resource: t10k-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "let dataset = MNIST(batchSize: batchSize, flattening: true, normalizing: true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a generator and a discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "var generator = Generator()\n",
    "var discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating optimisers for the generator and the discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need an optimization algorithm for both the models. In each case, we'll use the Adam optimisation algorithm. It's a popular choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "let optG = Adam(for: generator, learningRate: 2e-4, beta1: 0.5)\n",
    "let optD = Adam(for: discriminator, learningRate: 2e-4, beta1: 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to save a grid of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `saveImageGrid()` function generates a nice grid of images to look at the output of the GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "func saveImageGrid(_ testImage: Tensor<Float>, name: String) throws {\n",
    "    var gridImage = testImage.reshaped(\n",
    "        to: [\n",
    "            testImageGridSize, testImageGridSize,\n",
    "            imageHeight, imageWidth,\n",
    "        ])\n",
    "    // Add padding.\n",
    "    gridImage = gridImage.padded(forSizes: [(0, 0), (0, 0), (1, 1), (1, 1)], with: 1)\n",
    "    // Transpose to create single image.\n",
    "    gridImage = gridImage.transposed(withPermutations: [0, 2, 1, 3])\n",
    "    gridImage = gridImage.reshaped(\n",
    "        to: [\n",
    "            (imageHeight + 2) * testImageGridSize,\n",
    "            (imageWidth + 2) * testImageGridSize,\n",
    "        ])\n",
    "    // Convert [-1, 1] range to [0, 1] range.\n",
    "    gridImage = (gridImage + 1) / 2\n",
    "\n",
    "    try saveImage(\n",
    "        gridImage, size: (gridImage.shape[0], gridImage.shape[1]), directory: outputFolder,\n",
    "        name: name)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train, we iterate through to our desired `epochCount`, runs training using both the Generator and the Discriminator, and then runs an inference to generate a grid of images and print out the current epoch, and the generator's loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[Epoch: 1] Loss-G: 1.127014\n",
      "[Epoch: 2] Loss-G: 1.1459562\n",
      "[Epoch: 3] Loss-G: 1.1477773\n",
      "[Epoch: 4] Loss-G: 1.1610749\n",
      "[Epoch: 5] Loss-G: 1.1275166\n",
      "[Epoch: 6] Loss-G: 1.1709677\n",
      "[Epoch: 7] Loss-G: 1.1521204\n",
      "[Epoch: 8] Loss-G: 1.1473638\n",
      "[Epoch: 9] Loss-G: 1.131887\n",
      "[Epoch: 10] Loss-G: 1.1520165\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "\n",
    "// Start training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    // Start training phase.\n",
    "    Context.local.learningPhase = .training\n",
    "    for i in 0 ..< dataset.trainingSize / batchSize {\n",
    "        // Perform alternative update.\n",
    "        // Update generator.\n",
    "        let vec1 = sampleVector(size: batchSize)\n",
    "\n",
    "        let ùõÅgenerator = generator.gradient { generator -> Tensor<Float> in\n",
    "            let fakeImages = generator(vec1)\n",
    "            let fakeLogits = discriminator(fakeImages)\n",
    "            let loss = generatorLoss(fakeLogits: fakeLogits)\n",
    "            return loss\n",
    "        }\n",
    "        optG.update(&generator, along: ùõÅgenerator)\n",
    "\n",
    "        // Update discriminator.\n",
    "        let realImages = dataset.trainingImages.minibatch(at: i, batchSize: batchSize)\n",
    "        let vec2 = sampleVector(size: batchSize)\n",
    "        let fakeImages = generator(vec2)\n",
    "\n",
    "        let ùõÅdiscriminator = discriminator.gradient { discriminator -> Tensor<Float> in\n",
    "            let realLogits = discriminator(realImages)\n",
    "            let fakeLogits = discriminator(fakeImages)\n",
    "            let loss = discriminatorLoss(realLogits: realLogits, fakeLogits: fakeLogits)\n",
    "            return loss\n",
    "        }\n",
    "        optD.update(&discriminator, along: ùõÅdiscriminator)\n",
    "    }\n",
    "\n",
    "    // Start inference phase.\n",
    "    Context.local.learningPhase = .inference\n",
    "    let testImage = generator(sampleVector(size: testImageGridSize * testImageGridSize))\n",
    "\n",
    "    do {\n",
    "        try saveImageGrid(testImage, name: \"epoch-\\(epoch)-output\")\n",
    "    } catch {\n",
    "        print(\"Could not save image grid with error: \\(error)\")\n",
    "    }\n",
    "\n",
    "    let lossG = generatorLoss(fakeLogits: testImage)\n",
    "    print(\"[Epoch: \\(epoch)] Loss-G: \\(lossG)\")\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
