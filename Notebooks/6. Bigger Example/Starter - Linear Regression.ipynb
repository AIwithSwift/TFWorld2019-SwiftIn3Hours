{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Starter - Linear Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Swift","language":"swift","name":"swift"},"language_info":{"file_extension":".swift","mimetype":"text/x-swift","name":"swift","version":""}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bChC2l3EPmoi"},"source":["# Starter - Linear Regression\n","\n","**‚ö†Ô∏è This is the starter version, for you to code along with live.**\n","\n","Simple linear regression (Width, Height, Sex) with multi-variable and categories.\n","\n","Dataset with Height, Weight, Sex statistics from: \n","\n","https://raw.githubusercontent.com/Dataweekends/zero_to_deep_learning_video/master/data/weight-height.csv\n","\n","**Swift with SciKit Learn MinMax normalization**\n","\n","Use Python/Pandas to import the dataset Use SciKit Learn to normalize values with MinMax scaler\n","Based on https://github.com/JacopoMangiavacchi/Swift-TensorFlow-Sample-Notebooks"]},{"cell_type":"markdown","metadata":{"id":"Gbr0BXbblDqP","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"1e0Bg-rxlE39","colab_type":"code","colab":{}},"source":["import Python\n","import TensorFlow"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6xabtdolOgL","colab_type":"text"},"source":["## Setting up"]},{"cell_type":"markdown","metadata":{"id":"12Jl9t5e8KsN","colab_type":"text"},"source":["We need to bring in numpy, pandas, io, requests, and sklearn.preprocessing from Python:"]},{"cell_type":"code","metadata":{"id":"FXcEiwjqlSGY","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7A9A826lIjs","colab_type":"text"},"source":["## Getting a dataset"]},{"cell_type":"markdown","metadata":{"id":"JkOqEdmLlamV","colab_type":"text"},"source":["We've got a helper function to get a Numpy normalised dataset. It uses the Python requests and pandas library to download and read the CSV file for the data, as well as SKLearn's Prepocessing library and numpy arrays. Lots of Python!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TgiX5mzQ5vTd","colab":{}},"source":["func getNumpyNormalizedDataset() -> (PythonObject, PythonObject) \n","{\n","  let url=\"https://raw.githubusercontent.com/Dataweekends/zero_to_deep_learning_video/master/data/weight-height.csv\"\n","\n","  // more code goes here\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"seUJ8reJmGbc","colab_type":"text"},"source":["## Creating the model"]},{"cell_type":"markdown","metadata":{"id":"35TtsfUOmNIF","colab_type":"text"},"source":["As usual, we need to create a `struct` to represent our model, adhering to the  [`Layer` Protocol](https://www.tensorflow.org/swift/api_docs/Protocols/Layer).\n","\n","Since this is a bit of a contrived example, we actually only need layer (a [`Dense` layer](https://www.tensorflow.org/swift/api_docs/Structs/Dense)) that takes an `inputSize` and an `outputSize`, and is activated with [`identity`](https://www.tensorflow.org/swift/api_docs/Functions.html#identity_:). We use `identity` because we just want it to output a linear function of input.\n","\n","We create an initialiser, because we need to be able to take a variable number of variables. The default is 1. Inside the intitialiser, we define the layer.\n","\n","We'll also need to provide a definition of our `@differentiable` `func`, `callAsFunction()`. In this case, we want it to return the `input` passed through the single layer.\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_e1hzXeb8J5d","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EQlyIlsOnv74","colab_type":"text"},"source":["## Load our dataset "]},{"cell_type":"markdown","metadata":{"id":"G3ikd3xKnzJ5","colab_type":"text"},"source":["We need to get some x and y data, each in the form of a `PythonObject`, using the helper function we defined `getNumpyNormalizedDataset()`.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JdGxV6K2VZ2X","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v9VaRPo5oHnQ","colab_type":"text"},"source":["We also need to create arrays for each:"]},{"cell_type":"code","metadata":{"id":"u0vsXtNzoH_1","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4O-ErJBoLIn","colab_type":"text"},"source":["And then a native Swift for TensorFlow `Tensor<Float>`, for each of them:"]},{"cell_type":"code","metadata":{"id":"yJRdCEzkoLm7","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSlMsTC1oZ_T","colab_type":"text"},"source":["## Creating an instance of our model"]},{"cell_type":"markdown","metadata":{"id":"x6xb5CzGocxX","colab_type":"text"},"source":["We want a 3 variable instance of our model:"]},{"cell_type":"code","metadata":{"id":"RLAbtnUPobyF","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AtTNdGIWoSZZ","colab_type":"text"},"source":["## Creating an optimizer"]},{"cell_type":"markdown","metadata":{"id":"YibQSyouoTy9","colab_type":"text"},"source":["We'll need an optimizer. SGD will do fine here:\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OkEgM40GQGKG","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4YsZpaqoiad","colab_type":"text"},"source":["## Training the model"]},{"cell_type":"markdown","metadata":{"id":"OcYHb9u9ok5b","colab_type":"text"},"source":["First, we need a hyperparameter for epochs:"]},{"cell_type":"code","metadata":{"id":"asNWI2ZxonLz","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T0L0gkT8ooQE","colab_type":"text"},"source":["Then we need a training loop. \n","\n","For each epoch that we train, we:\n","\n","* calculate the cost and the gradient, and return the error using `meanSquaredError()` between the predicted and the expected\n","* update the model's optimizer along the gradient ùõÅ\n","* occasionally print out the current epoch and cost"]},{"cell_type":"code","metadata":{"id":"zNk-AKTBoiCm","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVVHjSlspmYY","colab_type":"text"},"source":["## Testing the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LOmonwRSVqui","colab":{}},"source":["//print(model.inferring(from:[[0.7, 0, 1]])) //Height, Female, Male\n","// [[0.66004163]]"],"execution_count":0,"outputs":[]}]}