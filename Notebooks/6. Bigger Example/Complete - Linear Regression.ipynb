{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Complete - Linear Regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Swift","language":"swift","name":"swift"},"language_info":{"file_extension":".swift","mimetype":"text/x-swift","name":"swift","version":""}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bChC2l3EPmoi"},"source":["# Complete - Linear Regression\n","\n","Simple linear regression (Width, Height, Sex) with multi-variable and categories.\n","\n","Dataset with Height, Weight, Sex statistics from: \n","\n","https://raw.githubusercontent.com/Dataweekends/zero_to_deep_learning_video/master/data/weight-height.csv\n","\n","**Swift with SciKit Learn MinMax normalization**\n","\n","Use Python/Pandas to import the dataset Use SciKit Learn to normalize values with MinMax scaler\n","Based on https://github.com/JacopoMangiavacchi/Swift-TensorFlow-Sample-Notebooks"]},{"cell_type":"markdown","metadata":{"id":"Gbr0BXbblDqP","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"1e0Bg-rxlE39","colab_type":"code","colab":{}},"source":["import Python\n","import TensorFlow"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r6xabtdolOgL","colab_type":"text"},"source":["## Setting up"]},{"cell_type":"code","metadata":{"id":"FXcEiwjqlSGY","colab_type":"code","colab":{}},"source":["let numpy = Python.import(\"numpy\")\n","let pandas = Python.import(\"pandas\")\n","let io = Python.import(\"io\")\n","let requests = Python.import(\"requests\")\n","let preprocessing = Python.import(\"sklearn.preprocessing\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7A9A826lIjs","colab_type":"text"},"source":["## Getting a dataset"]},{"cell_type":"markdown","metadata":{"id":"JkOqEdmLlamV","colab_type":"text"},"source":["We've got a helper function to get a Numpy normalised dataset. It uses the Python requests and pandas library to download and read the CSV file for the data, as well as SKLearn's Prepocessing library and numpy arrays. Lots of Python!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TgiX5mzQ5vTd","colab":{}},"source":["func getNumpyNormalizedDataset() -> (PythonObject, PythonObject) \n","{\n","    let url=\"https://raw.githubusercontent.com/Dataweekends/zero_to_deep_learning_video/master/data/weight-height.csv\"\n","    let s = requests.get(url).content\n","    let df = pandas.read_csv(io.StringIO(s.decode(\"utf-8\")))\n","\n","    let dummies = pandas.get_dummies(df[[\"Gender\"]])\n","    let transformed = pandas.concat([df[[\"Height\", \"Weight\"]], dummies], 1)\n","    print(transformed)\n","\n","    let X = transformed[[\"Height\",\"Gender_Female\",\"Gender_Male\"]].values\n","    let Y = transformed[[\"Weight\"]].values\n","\n","    let scaler = preprocessing.MinMaxScaler()\n","    let xNP = numpy.array(scaler.fit_transform(X))\n","    let yNP = numpy.array(scaler.fit_transform(Y))  \n","    \n","    return (xNP, yNP)\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"seUJ8reJmGbc","colab_type":"text"},"source":["## Creating the model"]},{"cell_type":"markdown","metadata":{"id":"35TtsfUOmNIF","colab_type":"text"},"source":["As usual, we need to create a `struct` to represent our model, adhering to the  [`Layer` Protocol](https://www.tensorflow.org/swift/api_docs/Protocols/Layer).\n","\n","Since this is a bit of a contrived example, we actually only need layer (a [`Dense` layer](https://www.tensorflow.org/swift/api_docs/Structs/Dense)) that takes an `inputSize` and an `outputSize`, and is activated with [`identity`](https://www.tensorflow.org/swift/api_docs/Functions.html#identity_:). We use `identity` because we just want it to output a linear function of input.\n","\n","We create an initialiser, because we need to be able to take a variable number of variables. The default is 1. Inside the intitialiser, we define the layer.\n","\n","We'll also need to provide a definition of our `@differentiable` `func`, `callAsFunction()`. In this case, we want it to return the `input` passed through the single layer.\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_e1hzXeb8J5d","colab":{}},"source":["struct LinearRegression: Layer \n","{\n","    var layer: Dense<Float>\n","    init(variables: Int = 1) \n","    {\n","        layer = Dense<Float>(inputSize: variables, outputSize: 1, activation: identity)\n","    }\n","\n","    @differentiable func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float>\n","    {\n","       return layer(input)\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EQlyIlsOnv74","colab_type":"text"},"source":["## Load our dataset "]},{"cell_type":"markdown","metadata":{"id":"G3ikd3xKnzJ5","colab_type":"text"},"source":["We need to get some x and y data, each in the form of a `PythonObject`, using the helper function we sefined `getNumpyNormalizedDataset()`.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JdGxV6K2VZ2X","colab":{}},"source":["let (xNP, yNP) = getNumpyNormalizedDataset()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v9VaRPo5oHnQ","colab_type":"text"},"source":["We also need to create arrays for each:"]},{"cell_type":"code","metadata":{"id":"u0vsXtNzoH_1","colab_type":"code","colab":{}},"source":["let xArray = xNP.tolist().flatMap{ $0.map{ Float($0)! }}\n","let yArray = yNP.tolist().flatMap{ $0.map{ Float($0)! }}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4O-ErJBoLIn","colab_type":"text"},"source":["And then a native Swift for TensorFlow `Tensor`, for each of them:"]},{"cell_type":"code","metadata":{"id":"yJRdCEzkoLm7","colab_type":"code","colab":{}},"source":["let x = Tensor<Float>(shape: [10000, 3], scalars: xArray)\n","let y = Tensor<Float>(shape: [10000, 1], scalars: yArray)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oSlMsTC1oZ_T","colab_type":"text"},"source":["## Creating an instance of our model"]},{"cell_type":"markdown","metadata":{"id":"x6xb5CzGocxX","colab_type":"text"},"source":["We want a 3 variable instance of our model:"]},{"cell_type":"code","metadata":{"id":"RLAbtnUPobyF","colab_type":"code","colab":{}},"source":["var model = LinearRegression(variables: 3)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AtTNdGIWoSZZ","colab_type":"text"},"source":["## Creating an optimizer"]},{"cell_type":"markdown","metadata":{"id":"YibQSyouoTy9","colab_type":"text"},"source":["We'll need an optimizer. SGD will do fine here:\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OkEgM40GQGKG","colab":{}},"source":["let optimizer = SGD(for: model, learningRate: 0.03)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d4YsZpaqoiad","colab_type":"text"},"source":["## Training the model"]},{"cell_type":"markdown","metadata":{"id":"OcYHb9u9ok5b","colab_type":"text"},"source":["First, we need a hyperparameter for epochs:"]},{"cell_type":"code","metadata":{"id":"asNWI2ZxonLz","colab_type":"code","colab":{}},"source":["let epochs = 2000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T0L0gkT8ooQE","colab_type":"text"},"source":["Then we need a training loop. \n","\n","For each epoch that we train, we:\n","\n","* calculate the cost and the gradient, and return the error using `meanSquaredError()` between the predicted and the expected\n","* update the model's optimizer along the gradient ùõÅ\n","* occasionally print out the current epoch and cost"]},{"cell_type":"code","metadata":{"id":"zNk-AKTBoiCm","colab_type":"code","colab":{}},"source":["for epoch in 1...epochs {\n","    let (cost, ùõÅmodel) = model.valueWithGradient { m -> Tensor<Float> in\n","        let ≈∑ = m(x)\n","        return meanSquaredError(predicted: ≈∑, expected: y)\n","    }\n","    optimizer.update(&model, along: ùõÅmodel)\n","  \n","    if epoch % 100 == 0 {\n","        print(\"Epoch: \\(epoch) Cost: \\(cost)\")\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVVHjSlspmYY","colab_type":"text"},"source":["## Testing the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LOmonwRSVqui","outputId":"61317e3d-a26d-4612-ce5d-d1986ce7db64","executionInfo":{"status":"ok","timestamp":1572287088017,"user_tz":240,"elapsed":1878,"user":{"displayName":"Paris B-A","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATPYgh7Oradnt-89Tt0-SyerXDc8Z985jmLS2U=s64","userId":"01326454337734597812"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(model.inferring(from:[[0.7, 0, 1]])) //Height, Female, Male\n","// [[0.66004163]]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.66004163]]\r\n"],"name":"stdout"}]}]}