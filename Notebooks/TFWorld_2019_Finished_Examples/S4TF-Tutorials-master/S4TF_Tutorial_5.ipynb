{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyCcF45zBQ3E"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors. [Licensed under the Apache License, Version 2.0](#scrollTo=y_UVSRtBBsJk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPII1rGR2rF9",
    "scrolled": true
   },
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
    "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "// you may not use this file except in compliance with the License.\n",
    "// You may obtain a copy of the License at\n",
    "//\n",
    "// https://www.apache.org/licenses/LICENSE-2.0\n",
    "//\n",
    "// Unless required by applicable law or agreed to in writing, software\n",
    "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "// See the License for the specific language governing permissions and\n",
    "// limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHI3vyhv5p85"
   },
   "source": [
    "# Dogs vs Cats Image Classification Without Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nk9wIGismSiu"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVi775ZJ2bsy"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/13lBsht3Wa4GjKKkA47JCrd54XikhNX2E\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"Link to be updated\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />GitHub link to be updated accordingly</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DCxmvkku5R-v"
   },
   "source": [
    "\n",
    "\n",
    "In this tutorial, we will discuss how to classify images into pictures of cats or pictures of dogs. We'll build an image classifier using `Layer` and load data by creating training and validation tensors of images as well as their corresponding labels.\n",
    "\n",
    "## Specific concepts that will be covered:\n",
    "In the process, we will build practical experience and develop intuition around the following concepts:\n",
    "\n",
    "* Building _data input pipelines_  — How can we efficiently work with data on disk to interface with our model? \n",
    "* _Overfitting_ - what is it, how to identify it?\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "**Before you begin**\n",
    "\n",
    "Before running the code in this notebook, reset the runtime by going to **Runtime -> Reset all runtimes** in the menu above. If you have been working through several notebooks, this will help you avoid reaching Colab's memory limits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAcmWrRy512Q"
   },
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z_IfI4an53t7"
   },
   "source": [
    "Let's start by importing required packages:\n",
    "\n",
    "*   glob — to read files and directory structure.\n",
    "*   numpy — for some matrix math outside of TensorFlow.\n",
    "*   matplotlib.pyplot — to plot the graph and display images in our training and validation data.\n",
    "*  PIL — to view images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ektHrmri503Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatal error: 'try!' expression unexpectedly raised an error: Python exception: No module named 'PIL': file /swift-base/swift/stdlib/public/Python/Python.swift, line 683\r\n",
      "Current stack trace:\r\n",
      "0    libswiftCore.so                    0x00007f49b5f2e810 swift_reportError + 50\r\n",
      "1    libswiftCore.so                    0x00007f49b5fa0180 _swift_stdlib_reportFatalErrorInFile + 115\r\n",
      "2    libswiftCore.so                    0x00007f49b5ca75ee <unavailable> + 1471982\r\n",
      "3    libswiftCore.so                    0x00007f49b5ca71f7 <unavailable> + 1470967\r\n",
      "4    libswiftCore.so                    0x00007f49b5ca77d8 <unavailable> + 1472472\r\n",
      "5    libswiftCore.so                    0x00007f49b5ca5a90 _assertionFailure(_:_:file:line:flags:) + 517\r\n",
      "6    libswiftCore.so                    0x00007f49b5cd1ab6 <unavailable> + 1645238\r\n",
      "7    libswiftPython.so                  0x00007f49b6a597db <unavailable> + 67547\r\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Current stack trace:",
      "\tframe #3: 0x00007f49b68fc307 $__lldb_expr32`main at <Cell 5>:12:18"
     ]
    }
   ],
   "source": [
    "import TensorFlow\n",
    "import Foundation\n",
    "import Python\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "let subprocess = Python.import(\"subprocess\")\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "let os = Python.import(\"os\")\n",
    "let np = Python.import(\"numpy\")  // Make numpy available using np.\n",
    "let glob = Python.import(\"glob\")\n",
    "let pil = Python.import(\"PIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3fcURSS6S_i"
   },
   "source": [
    "To build our image classifier, we begin by downloading the dataset. The dataset we are using is a filtered version of the <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs. Cats</a> dataset from Kaggle (ultimately, this dataset is provided by Microsoft Research).\n",
    "\n",
    "In this Colab, we will make use of the `glob` and  `subprocess` module which will read data from disk. We therefore need to directly download *Dogs vs. Cats* from a URL and unzip it to the Colab filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00tAtxan6dbo"
   },
   "outputs": [],
   "source": [
    "public extension String {\n",
    "    @discardableResult\n",
    "    func shell(_ args: String...) -> String {\n",
    "        let (task, pipe) = (Process(), Pipe())\n",
    "        task.executableURL = URL(fileURLWithPath: self)\n",
    "        (task.arguments, task.standardOutput) = (args, pipe)\n",
    "        do    { try task.run() }\n",
    "        catch { print(\"Unexpected error: \\(error).\") }\n",
    "\n",
    "        let data = pipe.fileHandleForReading.readDataToEndOfFile()\n",
    "        return String(data: data, encoding: String.Encoding.utf8) ?? \"\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KT2rv2eX6d8b",
    "outputId": "78ac6620-297e-4493-b39f-bb45f085730d"
   },
   "outputs": [],
   "source": [
    "print(\"/bin/ls\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "17Ti6tx-tMCU"
   },
   "source": [
    "We'll now download and unzip the dataset using `subprocess` library via Python Interoperability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "Ejo6uVyR6fe6",
    "outputId": "c9629a23-5bb8-4c69-b3ee-eea984919c6a"
   },
   "outputs": [],
   "source": [
    "//let command = \"wget -nv -O- https://github.com/Ayush517/S4TF-Tutorials/raw/master/cats_and_dogs_filtered.tar.gz | tar xzf - -C .\"\n",
    "//subprocess.call(command, shell: true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zN86uRrg7UDc"
   },
   "source": [
    "The dataset we have downloaded has the following directory structure:\n",
    "\n",
    "<pre style=\"font-size: 10.0pt; font-family: Arial; line-height: 2; letter-spacing: 1.0pt;\" >\n",
    "<b>cats_and_dogs_filtered</b>\n",
    "|__ <b>train</b>\n",
    "    |______ <b>cats</b>: [cat.0.jpg, cat.1.jpg, cat.2.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
    "|__ <b>validation</b>\n",
    "    |______ <b>cats</b>: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ...]\n",
    "    |______ <b>dogs</b>: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
    "</pre>\n",
    "\n",
    "We can list the directories with the following terminal command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "knKyPw8_6gwb",
    "outputId": "da3d4f57-5164-42e2-afe9-dc71cf6e68a7"
   },
   "outputs": [],
   "source": [
    "print(\"/bin/ls/\".shell(\"-lh\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fOp3XH_7ngK"
   },
   "source": [
    "We'll now assign variables with the proper file path for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiH6anOH6jYa"
   },
   "outputs": [],
   "source": [
    "let catTrainList = glob.glob(\"cats_and_dogs_filtered/train/cats/*.jpg\")\n",
    "let dogTrainList = glob.glob(\"cats_and_dogs_filtered/train/dogs/*.jpg\")\n",
    "let trainList = glob.glob(\"cats_and_dogs_filtered/train/**/*.jpg\")\n",
    "\n",
    "let catTestList  = glob.glob(\"cats_and_dogs_filtered/validation/cats/*.jpg\")\n",
    "let dogTestList  = glob.glob(\"cats_and_dogs_filtered/validation/dogs/*.jpg\")\n",
    "let testList  = glob.glob(\"cats_and_dogs_filtered/validation/**/*.jpg\")\n",
    "\n",
    "for i in 0 ..< 5 {\n",
    "    np.random.shuffle(trainList)\n",
    "    np.random.shuffle(testList)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXLwOkkB7tQ6"
   },
   "source": [
    "### Understanding our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUpm3LAe7vDt"
   },
   "source": [
    "Let's look at how many cats and dogs images we have in our training and validation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "FJ6NetwZ7siu",
    "outputId": "d6689fab-46b5-452c-c795-32dbee20f177"
   },
   "outputs": [],
   "source": [
    "print(\"total training cat images: \\(catTrainList.count)\")\n",
    "print(\"total training dog images: \\(dogTrainList.count)\")\n",
    "\n",
    "print(\"total validation cat images: \\(catTestList.count)\")\n",
    "print(\"total validation dog images: \\(dogTestList.count)\")\n",
    "print(\"--\")\n",
    "print(\"Total training images: \\(trainList.count)\")\n",
    "print(\"Total validation images: \\(testList.count)\")\n",
    "\n",
    "print(Python.type(trainList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akDk2rmO70un"
   },
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQ7KrBqH71L0"
   },
   "source": [
    "Images must be formatted into appropriately pre-processed floating point tensors before being fed into the network. The steps involved in preparing these images are:\n",
    "\n",
    "1. Read images from the disk.\n",
    "2. Decode the contents of these images into their RGB bytes.\n",
    "3. Convert them into floating point tensors.\n",
    "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, to better match the range expected by the initial neural network weights.\n",
    "\n",
    "We have done this in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRAT9M538M82"
   },
   "source": [
    "The `tensor(path:)` function takes the image path as input and outputs a tuple of the resized image tensor and its corresponding label.\n",
    "\n",
    "The `tensors(fromList:, valueCount:)` function takes in a list of paths and the number of tensors to be produced in the output tensor as input. While processing, it prints the number of images processed so that we can have an understanding of how much process is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DC85ego6kmK"
   },
   "outputs": [],
   "source": [
    "// Function `tensor(path:)` returns the resized image tensor and it's corresponding label.\n",
    "\n",
    "func tensor(path: String) -> (Tensor<Float>, Int32) {\n",
    "    let img = pil.Image.open(path)\n",
    "    var image = np.array(img, dtype: np.float32) * (1.0 / 255)\n",
    "    var imageTensor = Tensor<Float>(numpy: image)!\n",
    "    imageTensor = imageTensor.expandingShape(at: 0)\n",
    "    imageTensor = Raw.resizeArea(images: imageTensor , size: [150, 150])\n",
    "    \n",
    "    let label: Int32 = path.contains(\"dog.\") ? 0 : 1\n",
    "    \n",
    "    return (imageTensor, label)\n",
    "}\n",
    "\n",
    "// Function `tensors(fromList:valueCount:)` returns the entire list converted to tensors of images and labels from `tensor(path:)` function.\n",
    "func tensors(fromList: PythonObject, valueCount: Int) -> (Tensor<Float>, Tensor<Int32>) {\n",
    "    let batchFiles = fromList[0..<valueCount]\n",
    "    var labels = [Int32]()\n",
    "    var x: Tensor<Float>\n",
    "    var y: Tensor<Int32>\n",
    "    var start: Int\n",
    "\n",
    "    // Load first image.\n",
    "    let path: String = String(batchFiles[0]) ?? \"\"\n",
    "    let data = tensor(path: path)\n",
    "    x = data.0\n",
    "    labels.append(data.1)\n",
    "\n",
    "    // Load rest of the images.\n",
    "    var numberOfFilesDone = 1\n",
    "    for file in batchFiles[1..<valueCount] {\n",
    "        let path = String(file) ?? \"\"\n",
    "        let data = tensor(path: path)\n",
    "        let tensor = data.0\n",
    "        labels.append(data.1)\n",
    "        x = Tensor(concatenating: [x, tensor], alongAxis: 0)\n",
    "        numberOfFilesDone += 1\n",
    "        if numberOfFilesDone.isMultiple(of: 10) {\n",
    "            print(\"\", (numberOfFilesDone), separator: \" \", terminator:\"\")\n",
    "        }\n",
    "        if numberOfFilesDone.isMultiple(of: 100) {\n",
    "            print(\"\")\n",
    "        }\n",
    "    }\n",
    "    print(\"\")\n",
    "    y = Tensor<Int32>(labels)\n",
    "    return (x, y)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7t-Xyds8dOm"
   },
   "source": [
    "After defining our generators for images and labels, we will load those images and labels in tensor arrays, thereby creating our `trainTensors` and `testTensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "w9T1CsET6mVn",
    "outputId": "a6b0e303-1194-4c2e-ab77-dee52c4d3d4b"
   },
   "outputs": [],
   "source": [
    "let trainTensors = tensors(fromList: trainList, valueCount: trainList.count)\n",
    "let trainImageTensors = trainTensors.0\n",
    "let trainLabelTensors = trainTensors.1\n",
    "print(trainImageTensors.shape)\n",
    "print(trainLabelTensors.shape)\n",
    "let testTensors = tensors(fromList: testList, valueCount: testList.count)\n",
    "let testImageTensors = testTensors.0\n",
    "let testLabelTensors = testTensors.1\n",
    "print(testImageTensors.shape)\n",
    "print(testLabelTensors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RW_oP9vd83AT"
   },
   "source": [
    "### Visualizing Training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoeLuQjY83nZ"
   },
   "source": [
    "We can visualize our training images by creating functions to plot images from their paths or tensors, and then plotting a few of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wZaQBU0R6n-d"
   },
   "outputs": [],
   "source": [
    "func plotImages(_ image: Tensor<Float>) {\n",
    "    let numpyImage = image.makeNumpyArray()\n",
    "    plt.imshow(numpyImage)\n",
    "    plt.show()\n",
    "}\n",
    "\n",
    "func plotImages(from path: String) {\n",
    "    let img = pil.Image.open(path)\n",
    "    let image = np.array(img) * (1.0 / 255)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QnO7CzvV6psg",
    "outputId": "070901e0-9d94-48ba-9ada-b966d28c1b9a"
   },
   "outputs": [],
   "source": [
    "let images = trainList[0..<5]\n",
    "for i in 0..<5 {\n",
    "    plotImages(from: String(images[i])!)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pyb5bsh_9Idt"
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk5ikBiM9JA8"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "The model consists of four convolution blocks with a max pool layer in each of them. Then we have a fully connected layer with 512 units, with a `relu` activation function. The model will output class probabilities for two classes — dogs and cats — using `softmax`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPf9jf2p6rE-"
   },
   "outputs": [],
   "source": [
    "struct Classifier: Layer {\n",
    "    typealias Input = Tensor<Float>\n",
    "    typealias Output = Tensor<Float>\n",
    "\n",
    "    var conv1a = Conv2D<Float>(filterShape: (3, 3, 3, 32), activation: relu)\n",
    "    var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1b = Conv2D<Float>(filterShape: (3, 3, 32, 64), activation: relu)\n",
    "    var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1c = Conv2D<Float>(filterShape: (3, 3, 64, 128), activation: relu)\n",
    "    var pool3 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var conv1d = Conv2D<Float>(filterShape: (3, 3, 128, 128), activation: relu)\n",
    "    var pool4 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
    "    \n",
    "    var flatten = Flatten<Float>()\n",
    "    var layer1a = Dense<Float>(inputSize: 6272, outputSize: 512, activation: relu)\n",
    "    var layer1b = Dense<Float>(inputSize: 512, outputSize: 2, activation: softmax)\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Input) -> Output {\n",
    "        var convolved1 = input.sequenced(through: conv1a, pool1)\n",
    "        var convolved2 = convolved1.sequenced(through: conv1b, pool2)\n",
    "        var convolved3 = convolved2.sequenced(through: conv1c, pool3)\n",
    "        var convolved4 = convolved3.sequenced(through: conv1d, pool4)\n",
    "        return convolved4.sequenced(through: flatten, layer1a, layer1b)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_3UQ6ef9N5b"
   },
   "source": [
    "### Compile the model\n",
    "\n",
    "As usual, we will use the `adam` optimizer. Since we are output a softmax categorization, we'll use `softmaxCrossEntropy` as the loss function. We would also like to look at the training and validation accuracy on each epoch as we train our network, so we are passing in the metrics argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "MSNPc99r6s08",
    "outputId": "bba58b93-e813-4dca-e23f-bb98ebcf6686"
   },
   "outputs": [],
   "source": [
    "let tensor = Tensor<Float>(zeros:[100, 150, 150, 3])\n",
    "var classifier = Classifier()\n",
    "var optimizer = Adam(for: classifier, learningRate: 0.001)\n",
    "classifier(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZ1o31qE6uGz"
   },
   "outputs": [],
   "source": [
    "let epochCount = 100\n",
    "let batchSize = 100\n",
    "\n",
    "// Extract a batch of size batchSize.\n",
    "func minibatch<Scalar>(in x: Tensor<Scalar>, at index: Int) -> Tensor<Scalar> {\n",
    "    let start = index * batchSize\n",
    "    return x[start..<start+batchSize]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0YEIbAT-m3E"
   },
   "outputs": [],
   "source": [
    "var trainingAccuracy: [Float] = []\n",
    "var validationAccuracy: [Float] = []\n",
    "var trainingLoss: [Float] = []\n",
    "var validationLoss: [Float] = []\n",
    "var epochsRange: [Int] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJvC4F3O9bTW"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vuGBD1uY9bt6"
   },
   "source": [
    "It's time to train our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RY0hIJK36vnT",
    "outputId": "55146815-61ce-4675-daf0-e7b45ea45b5e"
   },
   "outputs": [],
   "source": [
    "print(\"Beginning training...\")\n",
    "\n",
    "struct Statistics {\n",
    "    var correctGuessCount: Int = 0\n",
    "    var totalGuessCount: Int = 0\n",
    "    var totalLoss: Float = 0\n",
    "}\n",
    "\n",
    "// The training loop.\n",
    "for epoch in 1...epochCount {\n",
    "    epochsRange.append(epoch)\n",
    "    var trainStats = Statistics()\n",
    "    var testStats = Statistics()\n",
    "    Context.local.learningPhase = .training\n",
    "    for i in 0..<Int(trainList.count) / batchSize {\n",
    "        let x = minibatch(in: trainImageTensors, at: i)\n",
    "        let y = minibatch(in: trainLabelTensors, at: i)\n",
    "        // Compute the gradient with respect to the model.\n",
    "        let 𝛁model = classifier.gradient { classifier -> Tensor<Float> in\n",
    "            let ŷ = classifier(x)\n",
    "            let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
    "            trainStats.correctGuessCount += Int(\n",
    "              Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "            trainStats.totalGuessCount += batchSize\n",
    "            let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
    "            trainStats.totalLoss += loss.scalarized()\n",
    "            return loss\n",
    "        }\n",
    "        // Update the model's differentiable variables along the gradient vector.\n",
    "        optimizer.update(&classifier.allDifferentiableVariables, along: 𝛁model)\n",
    "    }\n",
    "\n",
    "    Context.local.learningPhase = .inference\n",
    "    for i in 0..<Int(testList.count) / batchSize {\n",
    "        let x = minibatch(in: testImageTensors, at: i)\n",
    "        let y = minibatch(in: testLabelTensors, at: i)\n",
    "        // Compute loss on test set.\n",
    "        let ŷ = classifier(x)\n",
    "        let correctPredictions = ŷ.argmax(squeezingAxis: 1) .== y\n",
    "        testStats.correctGuessCount += Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        testStats.totalGuessCount += batchSize\n",
    "        let loss = softmaxCrossEntropy(logits: ŷ, labels: y)\n",
    "        testStats.totalLoss += loss.scalarized()\n",
    "    }\n",
    "    \n",
    "    let trainAccuracy = Float(trainStats.correctGuessCount) / Float(trainStats.totalGuessCount)\n",
    "    let testAccuracy = Float(testStats.correctGuessCount) / Float(testStats.totalGuessCount)\n",
    "    \n",
    "    trainingAccuracy.append(trainAccuracy)\n",
    "    validationAccuracy.append(testAccuracy)\n",
    "    trainingLoss.append(trainStats.totalLoss)\n",
    "    validationLoss.append(testStats.totalLoss)\n",
    "    \n",
    "    print(\"\"\"\n",
    "          [Epoch \\(epoch)] \\\n",
    "          Training Loss: \\(trainStats.totalLoss), \\\n",
    "          Training Accuracy: \\(trainStats.correctGuessCount)/\\(trainStats.totalGuessCount) \\ \n",
    "          (\\(trainAccuracy)), \\\n",
    "          Test Loss: \\(testStats.totalLoss), \\\n",
    "          Test Accuracy: \\(testStats.correctGuessCount)/\\(testStats.totalGuessCount) \\\n",
    "          (\\(testAccuracy))\n",
    "          \"\"\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aRWzpR3q9ho6"
   },
   "source": [
    "### Visualizing results of the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zD0-Bvf9iD6"
   },
   "source": [
    "We'll now visualize the results we get after training our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "4h42Yr6O_3NR",
    "outputId": "0e363423-0f3e-4944-b8d0-a080a3a1316b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize: [12, 8])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Accuracy(l) vs Validation Accuracy(o)\")\n",
    "plt.plot(epochsRange, trainingAccuracy)\n",
    "plt.plot(epochsRange, validationAccuracy)\n",
    "var loc = \"lower right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Training Loss(u) vs Validation Loss(p)\")\n",
    "plt.plot(epochsRange, trainingLoss)\n",
    "plt.plot(epochsRange, validationLoss)\n",
    "loc = \"upper right\"\n",
    "plt.legend(loc)\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0ZIdzef94kG"
   },
   "source": [
    "As we can see from the plots, training accuracy and validation accuracy are off by large margin and our model has achieved only around **75%** accuracy on the validation set (depending on the number of epochs you trained for).\n",
    "\n",
    "This is a clear indication of overfitting. Once the training and validation curves start to diverge, our model has started to memorize the training data an is unable to perform well on the validation data."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "S4TF Tutorial 5",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
