{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "\n",
    "public struct CIFARExample: TensorGroup {\n",
    "    public var label: Tensor<Int32>\n",
    "    public var data: Tensor<Float>\n",
    "\n",
    "    public init(label: Tensor<Int32>, data: Tensor<Float>) {\n",
    "        self.label = label\n",
    "        self.data = data\n",
    "    }\n",
    "\n",
    "    public init<C: RandomAccessCollection>(\n",
    "        _handles: C\n",
    "    ) where C.Element: _AnyTensorHandle {\n",
    "        precondition(_handles.count == 2)\n",
    "        let labelIndex = _handles.startIndex\n",
    "        let dataIndex = _handles.index(labelIndex, offsetBy: 1)\n",
    "        label = Tensor<Int32>(handle: TensorHandle<Int32>(handle: _handles[labelIndex]))\n",
    "        data = Tensor<Float>(handle: TensorHandle<Float>(handle: _handles[dataIndex]))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Foundation\n",
    "import TensorFlow\n",
    "\n",
    "#if canImport(FoundationNetworking)\n",
    "    import FoundationNetworking\n",
    "#endif\n",
    "\n",
    "public struct CIFAR10 {\n",
    "    public let trainingDataset: Dataset<CIFARExample>\n",
    "    public let testDataset: Dataset<CIFARExample>\n",
    "\n",
    "    public init() {\n",
    "        self.trainingDataset = Dataset<CIFARExample>(elements: loadCIFARTrainingFiles())\n",
    "        self.testDataset = Dataset<CIFARExample>(elements: loadCIFARTestFile())\n",
    "    }\n",
    "}\n",
    "\n",
    "func downloadCIFAR10IfNotPresent(to directory: String = \".\") {\n",
    "    let downloadPath = \"\\(directory)/cifar-10-batches-bin\"\n",
    "    let directoryExists = FileManager.default.fileExists(atPath: downloadPath)\n",
    "\n",
    "    guard !directoryExists else { return }\n",
    "\n",
    "    print(\"Downloading CIFAR dataset...\")\n",
    "    let archivePath = \"\\(directory)/cifar-10-binary.tar.gz\"\n",
    "    let archiveExists = FileManager.default.fileExists(atPath: archivePath)\n",
    "    if !archiveExists {\n",
    "        print(\"Archive missing, downloading...\")\n",
    "        do {\n",
    "            let downloadedFile = try Data(\n",
    "                contentsOf: URL(\n",
    "                    string: \"https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz\")!)\n",
    "            try downloadedFile.write(to: URL(fileURLWithPath: archivePath))\n",
    "        } catch {\n",
    "            print(\"Could not download CIFAR dataset, error: \\(error)\")\n",
    "            exit(-1)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(\"Archive downloaded, processing...\")\n",
    "\n",
    "    #if os(macOS)\n",
    "        let tarLocation = \"/usr/bin/tar\"\n",
    "    #else\n",
    "        let tarLocation = \"/bin/tar\"\n",
    "    #endif\n",
    "\n",
    "    let task = Process()\n",
    "    task.executableURL = URL(fileURLWithPath: tarLocation)\n",
    "    task.arguments = [\"xzf\", archivePath]\n",
    "    do {\n",
    "        try task.run()\n",
    "        task.waitUntilExit()\n",
    "    } catch {\n",
    "        print(\"CIFAR extraction failed with error: \\(error)\")\n",
    "    }\n",
    "\n",
    "    do {\n",
    "        try FileManager.default.removeItem(atPath: archivePath)\n",
    "    } catch {\n",
    "        print(\"Could not remove archive, error: \\(error)\")\n",
    "        exit(-1)\n",
    "    }\n",
    "\n",
    "    print(\"Unarchiving completed\")\n",
    "}\n",
    "\n",
    "func loadCIFARFile(named name: String, in directory: String = \".\") -> CIFARExample {\n",
    "    downloadCIFAR10IfNotPresent(to: directory)\n",
    "    let path = \"\\(directory)/cifar-10-batches-bin/\\(name)\"\n",
    "\n",
    "    let imageCount = 10000\n",
    "    guard let fileContents = try? Data(contentsOf: URL(fileURLWithPath: path)) else {\n",
    "        print(\"Could not read dataset file: \\(name)\")\n",
    "        exit(-1)\n",
    "    }\n",
    "    guard fileContents.count == 30_730_000 else {\n",
    "        print(\n",
    "            \"Dataset file \\(name) should have 30730000 bytes, instead had \\(fileContents.count)\")\n",
    "        exit(-1)\n",
    "    }\n",
    "\n",
    "    var bytes: [UInt8] = []\n",
    "    var labels: [Int64] = []\n",
    "\n",
    "    let imageByteSize = 3073\n",
    "    for imageIndex in 0..<imageCount {\n",
    "        let baseAddress = imageIndex * imageByteSize\n",
    "        labels.append(Int64(fileContents[baseAddress]))\n",
    "        bytes.append(contentsOf: fileContents[(baseAddress + 1)..<(baseAddress + 3073)])\n",
    "    }\n",
    "\n",
    "    let labelTensor = Tensor<Int64>(shape: [imageCount], scalars: labels)\n",
    "    let images = Tensor<UInt8>(shape: [imageCount, 3, 32, 32], scalars: bytes)\n",
    "\n",
    "    // Transpose from the CIFAR-provided N(CHW) to TF's default NHWC.\n",
    "    let imageTensor = Tensor<Float>(images.transposed(withPermutations: [0, 2, 3, 1]))\n",
    "\n",
    "    let mean = Tensor<Float>([0.485, 0.456, 0.406])\n",
    "    let std = Tensor<Float>([0.229, 0.224, 0.225])\n",
    "    let imagesNormalized = ((imageTensor / 255.0) - mean) / std\n",
    "\n",
    "    return CIFARExample(label: Tensor<Int32>(labelTensor), data: imagesNormalized)\n",
    "}\n",
    "\n",
    "func loadCIFARTrainingFiles() -> CIFARExample {\n",
    "    let data = (1..<6).map { loadCIFARFile(named: \"data_batch_\\($0).bin\") }\n",
    "    return CIFARExample(\n",
    "        label: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.label }),\n",
    "        data: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.data })\n",
    "    )\n",
    "}\n",
    "\n",
    "func loadCIFARTestFile() -> CIFARExample {\n",
    "    return loadCIFARFile(named: \"test_batch.bin\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "\n",
    "// Original Paper:\n",
    "// \"Deep Residual Learning for Image Recognition\"\n",
    "// Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "// https://arxiv.org/abs/1512.03385\n",
    "// using shortcut layer to connect BasicBlock layers (aka Option (B))\n",
    "public enum DataKind {\n",
    "    case cifar\n",
    "    case imagenet\n",
    "}\n",
    "\n",
    "public struct ConvBN: Layer {\n",
    "    public var conv: Conv2D<Float>\n",
    "    public var norm: BatchNorm<Float>\n",
    "\n",
    "    public init(\n",
    "        filterShape: (Int, Int, Int, Int),\n",
    "        strides: (Int, Int) = (1, 1),\n",
    "        padding: Padding = .valid\n",
    "    ) {\n",
    "        self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding)\n",
    "        self.norm = BatchNorm(featureCount: filterShape.3)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: conv, norm)\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualBasicBlockShortcut: Layer {\n",
    "    public var layer1: ConvBN\n",
    "    public var layer2: ConvBN\n",
    "    public var shortcut: ConvBN\n",
    "\n",
    "    public init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3) {\n",
    "        self.layer1 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.0, featureCounts.1),\n",
    "            strides: (2, 2),\n",
    "            padding: .same)\n",
    "        self.layer2 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),\n",
    "            strides: (1, 1),\n",
    "            padding: .same)\n",
    "        self.shortcut = ConvBN(\n",
    "            filterShape: (1, 1, featureCounts.0, featureCounts.3),\n",
    "            strides: (2, 2),\n",
    "            padding: .same)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return layer2(relu(layer1(input))) + shortcut(input)\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualBasicBlock: Layer {\n",
    "    public var layer1: ConvBN\n",
    "    public var layer2: ConvBN\n",
    "\n",
    "    public init(\n",
    "        featureCounts: (Int, Int, Int, Int),\n",
    "        kernelSize: Int = 3,\n",
    "        strides: (Int, Int) = (1, 1)\n",
    "    ) {\n",
    "        self.layer1 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.0, featureCounts.1),\n",
    "            strides: strides,\n",
    "            padding: .same)\n",
    "        self.layer2 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.3),\n",
    "            strides: strides,\n",
    "            padding: .same)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return layer2(relu(layer1(input)))\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualBasicBlockStack: Layer {\n",
    "    public var blocks: [ResidualBasicBlock] = []\n",
    "\n",
    "    public init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3, blockCount: Int) {\n",
    "        for _ in 0..<blockCount {\n",
    "            blocks += [ResidualBasicBlock(featureCounts: featureCounts, kernelSize: kernelSize)]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let blocksReduced = blocks.differentiableReduce(input) { last, layer in\n",
    "            layer(last)\n",
    "        }\n",
    "        return blocksReduced\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualConvBlock: Layer {\n",
    "    public var layer1: ConvBN\n",
    "    public var layer2: ConvBN\n",
    "    public var layer3: ConvBN\n",
    "    public var shortcut: ConvBN\n",
    "\n",
    "    public init(\n",
    "        featureCounts: (Int, Int, Int, Int),\n",
    "        kernelSize: Int = 3,\n",
    "        strides: (Int, Int) = (2, 2)\n",
    "    ) {\n",
    "        self.layer1 = ConvBN(\n",
    "            filterShape: (1, 1, featureCounts.0, featureCounts.1),\n",
    "            strides: strides)\n",
    "        self.layer2 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),\n",
    "            padding: .same)\n",
    "        self.layer3 = ConvBN(filterShape: (1, 1, featureCounts.2, featureCounts.3))\n",
    "        self.shortcut = ConvBN(\n",
    "            filterShape: (1, 1, featureCounts.0, featureCounts.3),\n",
    "            strides: strides,\n",
    "            padding: .same)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let tmp = relu(layer2(relu(layer1(input))))\n",
    "        return relu(layer3(tmp) + shortcut(input))\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualIdentityBlock: Layer {\n",
    "    public var layer1: ConvBN\n",
    "    public var layer2: ConvBN\n",
    "    public var layer3: ConvBN\n",
    "\n",
    "    public init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3) {\n",
    "        self.layer1 = ConvBN(filterShape: (1, 1, featureCounts.0, featureCounts.1))\n",
    "        self.layer2 = ConvBN(\n",
    "            filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.2),\n",
    "            padding: .same)\n",
    "        self.layer3 = ConvBN(filterShape: (1, 1, featureCounts.2, featureCounts.3))\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let tmp = relu(layer2(relu(layer1(input))))\n",
    "        return relu(layer3(tmp) + input)\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResidualIdentityBlockStack: Layer {\n",
    "    public var blocks: [ResidualIdentityBlock] = []\n",
    "\n",
    "    public init(featureCounts: (Int, Int, Int, Int), kernelSize: Int = 3, blockCount: Int) {\n",
    "        for _ in 0..<blockCount {\n",
    "            blocks += [ResidualIdentityBlock(featureCounts: featureCounts, kernelSize: kernelSize)]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let blocksReduced = blocks.differentiableReduce(input) { last, layer in\n",
    "            layer(last)\n",
    "        }\n",
    "        return blocksReduced\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResNetBasic: Layer {\n",
    "    public var l1: ConvBN\n",
    "    public var maxPool: MaxPool2D<Float>\n",
    "\n",
    "    public var l2a = ResidualBasicBlock(featureCounts: (64, 64, 64, 64))\n",
    "    public var l2b: ResidualBasicBlockStack\n",
    "\n",
    "    public var l3a = ResidualBasicBlockShortcut(featureCounts: (64, 128, 128, 128))\n",
    "    public var l3b: ResidualBasicBlockStack\n",
    "\n",
    "    public var l4a = ResidualBasicBlockShortcut(featureCounts: (128, 256, 256, 256))\n",
    "    public var l4b: ResidualBasicBlockStack\n",
    "\n",
    "    public var l5a = ResidualBasicBlockShortcut(featureCounts: (256, 512, 512, 512))\n",
    "    public var l5b: ResidualBasicBlockStack\n",
    "\n",
    "    public var avgPool: AvgPool2D<Float>\n",
    "    public var flatten = Flatten<Float>()\n",
    "    public var classifier: Dense<Float>\n",
    "\n",
    "    public init(dataKind: DataKind, layerBlockCounts: (Int, Int, Int, Int)) {\n",
    "        switch dataKind {\n",
    "        case .imagenet:\n",
    "            l1 = ConvBN(filterShape: (7, 7, 3, 64), strides: (2, 2), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2))\n",
    "            avgPool = AvgPool2D(poolSize: (7, 7), strides: (7, 7))\n",
    "            classifier = Dense(inputSize: 512, outputSize: 1000)\n",
    "        case .cifar:\n",
    "            l1 = ConvBN(filterShape: (3, 3, 3, 64), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (1, 1), strides: (1, 1))  // no-op\n",
    "            avgPool = AvgPool2D(poolSize: (4, 4), strides: (4, 4))\n",
    "            classifier = Dense(inputSize: 512, outputSize: 10)\n",
    "        }\n",
    "\n",
    "        l2b = ResidualBasicBlockStack(\n",
    "            featureCounts: (64, 64, 64, 64),\n",
    "            blockCount: layerBlockCounts.0)\n",
    "        l3b = ResidualBasicBlockStack(\n",
    "            featureCounts: (128, 128, 128, 128),\n",
    "            blockCount: layerBlockCounts.1)\n",
    "        l4b = ResidualBasicBlockStack(\n",
    "            featureCounts: (256, 256, 256, 256),\n",
    "            blockCount: layerBlockCounts.2)\n",
    "        l5b = ResidualBasicBlockStack(\n",
    "            featureCounts: (512, 512, 512, 512),\n",
    "            blockCount: layerBlockCounts.3)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let inputLayer = maxPool(relu(l1(input)))\n",
    "        let level2 = inputLayer.sequenced(through: l2a, l2b)\n",
    "        let level3 = level2.sequenced(through: l3a, l3b)\n",
    "        let level4 = level3.sequenced(through: l4a, l4b)\n",
    "        let level5 = level4.sequenced(through: l5a, l5b)\n",
    "        return level5.sequenced(through: avgPool, flatten, classifier)\n",
    "    }\n",
    "}\n",
    "\n",
    "extension ResNetBasic {\n",
    "    public enum Kind {\n",
    "        case resNet18\n",
    "        case resNet34\n",
    "    }\n",
    "\n",
    "    public init(inputKind: Kind, dataKind: DataKind) {\n",
    "        switch inputKind {\n",
    "        case .resNet18:\n",
    "            self.init(dataKind: dataKind, layerBlockCounts: (2, 2, 2, 2))\n",
    "        case .resNet34:\n",
    "            self.init(dataKind: dataKind, layerBlockCounts: (3, 4, 6, 3))\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "public struct ResNet: Layer {\n",
    "    public var l1: ConvBN\n",
    "    public var maxPool: MaxPool2D<Float>\n",
    "\n",
    "    public var l2a = ResidualConvBlock(featureCounts: (64, 64, 64, 256), strides: (1, 1))\n",
    "    public var l2b: ResidualIdentityBlockStack\n",
    "\n",
    "    public var l3a = ResidualConvBlock(featureCounts: (256, 128, 128, 512))\n",
    "    public var l3b: ResidualIdentityBlockStack\n",
    "\n",
    "    public var l4a = ResidualConvBlock(featureCounts: (512, 256, 256, 1024))\n",
    "    public var l4b: ResidualIdentityBlockStack\n",
    "\n",
    "    public var l5a = ResidualConvBlock(featureCounts: (1024, 512, 512, 2048))\n",
    "    public var l5b: ResidualIdentityBlockStack\n",
    "\n",
    "    public var avgPool: AvgPool2D<Float>\n",
    "    public var flatten = Flatten<Float>()\n",
    "    public var classifier: Dense<Float>\n",
    "\n",
    "    public init(dataKind: DataKind, layerBlockCounts: (Int, Int, Int, Int)) {\n",
    "        switch dataKind {\n",
    "        case .imagenet:\n",
    "            l1 = ConvBN(filterShape: (7, 7, 3, 64), strides: (2, 2), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (3, 3), strides: (2, 2))\n",
    "            avgPool = AvgPool2D(poolSize: (7, 7), strides: (7, 7))\n",
    "            classifier = Dense(inputSize: 2048, outputSize: 1000)\n",
    "        case .cifar:\n",
    "            l1 = ConvBN(filterShape: (3, 3, 3, 64), padding: .same)\n",
    "            maxPool = MaxPool2D(poolSize: (1, 1), strides: (1, 1))  // no-op\n",
    "            avgPool = AvgPool2D(poolSize: (4, 4), strides: (4, 4))\n",
    "            classifier = Dense(inputSize: 2048, outputSize: 10)\n",
    "        }\n",
    "\n",
    "        l2b = ResidualIdentityBlockStack(\n",
    "            featureCounts: (256, 64, 64, 256),\n",
    "            blockCount: layerBlockCounts.0)\n",
    "        l3b = ResidualIdentityBlockStack(\n",
    "            featureCounts: (512, 128, 128, 512),\n",
    "            blockCount: layerBlockCounts.1)\n",
    "        l4b = ResidualIdentityBlockStack(\n",
    "            featureCounts: (1024, 256, 256, 1024),\n",
    "            blockCount: layerBlockCounts.2)\n",
    "        l5b = ResidualIdentityBlockStack(\n",
    "            featureCounts: (2048, 512, 512, 2048),\n",
    "            blockCount: layerBlockCounts.3)\n",
    "    }\n",
    "\n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        let inputLayer = maxPool(relu(l1(input)))\n",
    "        let level2 = inputLayer.sequenced(through: l2a, l2b)\n",
    "        let level3 = level2.sequenced(through: l3a, l3b)\n",
    "        let level4 = level3.sequenced(through: l4a, l4b)\n",
    "        let level5 = level4.sequenced(through: l5a, l5b)\n",
    "        return level5.sequenced(through: avgPool, flatten, classifier)\n",
    "    }\n",
    "}\n",
    "\n",
    "extension ResNet {\n",
    "    public enum Kind {\n",
    "        case resNet50\n",
    "        case resNet101\n",
    "        case resNet152\n",
    "    }\n",
    "\n",
    "    public init(inputKind: Kind, dataKind: DataKind) {\n",
    "        switch inputKind {\n",
    "        case .resNet50:\n",
    "            self.init(dataKind: dataKind, layerBlockCounts: (3, 4, 6, 3))\n",
    "        case .resNet101:\n",
    "            self.init(dataKind: dataKind, layerBlockCounts: (3, 4, 23, 3))\n",
    "        case .resNet152:\n",
    "            self.init(dataKind: dataKind, layerBlockCounts: (3, 8, 36, 3))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "error: <Cell 1>:7:15: error: use of unresolved identifier 'CIFAR10'\nlet dataset = CIFAR10()\n              ^~~~~~~\n\nerror: <Cell 1>:11:13: error: use of unresolved identifier 'ResNet'\nvar model = ResNet(inputKind: .resNet50, dataKind: .cifar)\n            ^~~~~~\n\n"
     ]
    }
   ],
   "source": [
    "import Datasets\n",
    "import ImageClassificationModels\n",
    "import TensorFlow\n",
    "\n",
    "let batchSize = 100\n",
    "\n",
    "let dataset = CIFAR10()\n",
    "let testBatches = dataset.testDataset.batched(batchSize)\n",
    "\n",
    "// Use the network sized for CIFAR-10\n",
    "var model = ResNet(inputKind: .resNet50, dataKind: .cifar)\n",
    "\n",
    "// the classic ImageNet optimizer setting diverges on CIFAR-10\n",
    "// let optimizer = SGD(for: model, learningRate: 0.1, momentum: 0.9)\n",
    "let optimizer = SGD(for: model, learningRate: 0.001)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "Context.local.learningPhase = .training\n",
    "\n",
    "for epoch in 1...10 {\n",
    "    var trainingLossSum: Float = 0\n",
    "    var trainingBatchCount = 0\n",
    "    let trainingShuffled = dataset.trainingDataset.shuffled(\n",
    "        sampleCount: 50000, randomSeed: Int64(epoch))\n",
    "    for batch in trainingShuffled.batched(batchSize) {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        let (loss, gradients) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
    "            let logits = model(images)\n",
    "            return softmaxCrossEntropy(logits: logits, labels: labels)\n",
    "        }\n",
    "        trainingLossSum += loss.scalarized()\n",
    "        trainingBatchCount += 1\n",
    "        optimizer.update(&model, along: gradients)\n",
    "    }\n",
    "    var testLossSum: Float = 0\n",
    "    var testBatchCount = 0\n",
    "    var correctGuessCount = 0\n",
    "    var totalGuessCount = 0\n",
    "    for batch in testBatches {\n",
    "        let (labels, images) = (batch.label, batch.data)\n",
    "        let logits = model(images)\n",
    "        testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()\n",
    "        testBatchCount += 1\n",
    "\n",
    "        let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
    "        correctGuessCount = correctGuessCount + Int(\n",
    "            Tensor<Int32>(correctPredictions).sum().scalarized())\n",
    "        totalGuessCount = totalGuessCount + batchSize\n",
    "    }\n",
    "\n",
    "    let accuracy = Float(correctGuessCount) / Float(totalGuessCount)\n",
    "    print(\n",
    "        \"\"\"\n",
    "          [Epoch \\(epoch)] \\\n",
    "          Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(accuracy)) \\\n",
    "          Loss: \\(testLossSum / Float(testBatchCount))\n",
    "          \"\"\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
