{"nbformat":4,"nbformat_minor":0,"metadata":{"file_extension":".py","kernelspec":{"display_name":"Swift","language":"swift","name":"swift"},"language_info":{"file_extension":".swift","mimetype":"text/x-swift","name":"swift","version":""},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"colab":{"name":"Meet TensorFlow! Training a Model - Starter.ipynb","provenance":[{"file_id":"1u_Saarvb1qQVxA4dq8pv3-k3ZaouwfSh","timestamp":1572307423069}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qq_n--SKNanf","colab_type":"text"},"source":["# Starter - Meet TensorFlow! Training a XOR Model"]},{"cell_type":"markdown","metadata":{"id":"u9SJrpjU5H_C","colab_type":"text"},"source":["**‚ö†Ô∏è This is the starter version, for you to code along with live.**"]},{"cell_type":"markdown","metadata":{"id":"16937WSdNank","colab_type":"text"},"source":["In this example, we assemble a multilayer peceptron network that can perform XOR. \n","\n","It's not very useful, but it showcases how you build up a model using layers, and how to execute training with that model. \n","\n","It's simple enough that you know whether it's correct... which is why we're doing it!\n"]},{"cell_type":"markdown","metadata":{"id":"jJZxT8xyTDXC","colab_type":"text"},"source":["## Setting up"]},{"cell_type":"markdown","metadata":{"id":"2bRvS7ipNsAf","colab_type":"text"},"source":["First, we need to `import` the TensorFlow framework:"]},{"cell_type":"code","metadata":{"id":"PbMmpBLrNann","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L7nCrdjhN0hv","colab_type":"text"},"source":["## Creating the model\n","\n","To represent our XOR neural network model, we need to create a `struct`, adhering to the  [`Layer` Protocol](https://www.tensorflow.org/swift/api_docs/Protocols/Layer) (which is part of Swift For TensorFlow's API). Ours is called `XORModel`.\n","\n","Inside the model, we want three layers:\n","* an input layer, to take the input\n","* a hidden layer \n","* an output layer, to provide the output\n","\n","All three layers should be a `Dense` layer (a [densely-connected layer](https://www.tensorflow.org/swift/api_docs/Structs/Dense)) that takes an `inputSize` and an `outputSize`. \n","\n","The `inputSize` specifies that the input to the layer is of that many values. Likewise `outputSize`, for the out of the layer.\n","\n","Each will have an activation using an `activation` function determines the output shape of each node in the layer. There are many available activations, but [ReLU](https://www.tensorflow.org/swift/api_docs/Functions#leakyrelu_:alpha:) and [Sigmoid](https://www.tensorflow.org/swift/api_docs/Functions#sigmoid_:) are common. \n","\n","For our three layers, we'll use `sigmoid`.\n","\n","We'll also need to provide a definition of our `@differentiable` `func`, `callAsFunction()`. In this case, we want it to return the `input` sequenced through (passed through) the three layers. \n","\n","Helpfully, the `Differentiable` `protocol` that comes with Swift for TensorFlow has a method, [`sequenced()`](https://www.tensorflow.org/swift/api_docs/Protocols/Differentiable#sequencedthrough:_:) that makes this trivial.\n","\n"]},{"cell_type":"code","metadata":{"id":"2812LRBTNant","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2ybin-B0Qy2o","colab_type":"text"},"source":["## Creating an instance of our model"]},{"cell_type":"markdown","metadata":{"id":"yKjOCu_RRBPM","colab_type":"text"},"source":["Here we need to create an instance of our XORModel Struct, which we defined above. This will be our model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kZRlD4utdPuX","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxDDiGpXQ3DQ","colab_type":"text"},"source":["## Creating an optimizer"]},{"cell_type":"markdown","metadata":{"id":"blHjk_IpRLV9","colab_type":"text"},"source":["And we need an [optimiser](https://www.tensorflow.org/swift/api_docs/Protocols/Optimizer), in this case we're going to use [stochastic gradient descent (SGD) optimiser](https://www.tensorflow.org/swift/api_docs/Classes/SGD), which we can get from the Swift for TensorFlow library.\n","\n","Our optimiser is, obviously, for the model instance we defined a moment ago, and wants a learning rate of about 0.02."]},{"cell_type":"code","metadata":{"id":"op5PRWVoQ2iu","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vlm3A-FKQ8MB","colab_type":"text"},"source":["##  Creating and labelling training data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Gqn5RlZaRvrh","colab_type":"text"},"source":["We need an array of type [`Tensor<Float>`](https://www.tensorflow.org/swift/api_docs/Structs/Tensor) to hold our training data (`[0, 0], [0, 1], [1, 0], [1, 1]`):"]},{"cell_type":"code","metadata":{"id":"zjyQoNqnQ7t4","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ttw6mJUSJZc","colab_type":"text"},"source":["And we need a similar one to mark/label the training data so that we know the correct outputs:\n"]},{"cell_type":"code","metadata":{"id":"KBRwcj0MSKX5","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nmq98WiPSQE9","colab_type":"text"},"source":["## Training the model"]},{"cell_type":"markdown","metadata":{"id":"dieIbtmdVvgB","colab_type":"text"},"source":["First, we need a hyperparameter for epochs (100,000 is about right here):"]},{"cell_type":"code","metadata":{"id":"CDt6kEjKVyWs","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8zAz5DDiWVM7","colab_type":"text"},"source":["Then we need a training loop. We train the model by iterating through our epochs, and each time update the gradient (the ùõÅ symbol, nabla, is often used to represent gradient). Our gradient is of type [`TangentVector`](https://www.tensorflow.org/swift/api_docs/Protocols/Differentiable#tangentvector), and represents a differentiable value‚Äôs derivatives.\n","\n","Each epoch, we set the predicted value to be our training data, and the expected value to be our training data, and calculate the loss using [`meanSquaredError()`](https://www.tensorflow.org/swift/api_docs/Functions#meansquarederrorpredicted:expected:).\n","\n","Every so often we also want to print out the epoch we're in, and the current loss, so we can watch the traning. We also need to return loss.\n","\n","Finally, we need to use our [optimizer](https://www.tensorflow.org/swift/api_docs/Protocols/Optimizer) to [update](https://www.tensorflow.org/swift/api_docs/Protocols/Optimizer#update_:along:) the differentiable variables, along the gradient.\n"]},{"cell_type":"code","metadata":{"id":"8QGopdwKNan3","colab_type":"code","colab":{}},"source":["// code goes here"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fwskbFpjNan7","colab_type":"text"},"source":["## Testing the model"]},{"cell_type":"markdown","metadata":{"id":"uLwxZwm64-rG","colab_type":"text"},"source":["Uncomment the following to test the model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uSC0vIJVv_Cj","colab":{}},"source":["//print(round(model.inferring(from: [[0, 0], [0, 1], [1, 0], [1, 1]])))"],"execution_count":0,"outputs":[]}]}