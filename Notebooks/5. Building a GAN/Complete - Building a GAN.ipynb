{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Swift","language":"swift","name":"swift"},"language_info":{"file_extension":".swift","mimetype":"text/x-swift","name":"swift","version":""},"colab":{"name":"Complete - Building a GAN.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"M4Q0R87raV1i","colab_type":"text"},"source":["# Complete - Building a GAN"]},{"cell_type":"markdown","metadata":{"id":"JVIJyE2IaV1n","colab_type":"text"},"source":["We're not here to teach the fundamentals of neural networks or ML, but we think GANs are a pretty neat demo. GANs (Generative Adversarial Networks) have two entirely separate networks (models) that work together/compete against each other to generate something.\n","\n","Their overarching goal is to generate new data that is somewhat similar to some of the data they were trained with.\n","    \n","Basically, the **generator** generates fake images that are then used by the **discriminator** to see if they're real. Working together, they both get cleverer and cleverer, until the discriminator cannot distinguish the difference between generator-generated images, and the real thing."]},{"cell_type":"markdown","metadata":{"id":"kQxYVlrFaV1q","colab_type":"text"},"source":["## Imports"]},{"cell_type":"markdown","metadata":{"id":"q9zGryN4aV1s","colab_type":"text"},"source":["We need `Foundation` so we can use the Swift types, `FoundationNetworking` so we can download stuff, `TensorFlow`, so we can use the machine learning bits and pieces, \n","\n","NOTE: If you're running this on your own local install then you might also need to import `Datasets` and `ModelSupport`, which helps you work with existing datasets and files. "]},{"cell_type":"code","metadata":{"id":"TyOmg8j5aV1u","colab_type":"code","colab":{}},"source":["import Foundation\n","import FoundationNetworking\n","import TensorFlow"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jV7fZ8w0bCds","colab_type":"text"},"source":["### Some support code\n","\n","This is a collection of convenience methods and helpers to write/read files, and such. It's quite long, so leave this section collapsed. The code here is a little beyond the scope of the session. Ask us, and if we have time we can go through it with you."]},{"cell_type":"markdown","metadata":{"id":"eR1-Vo_4bEYk","colab_type":"text"},"source":["We need to bring in some support Swift code that allows us to manipulate local files, download files, and get the MNIST dataset. You can expand this and read it if you want, but it's beyond the scope of this session."]},{"cell_type":"code","metadata":{"id":"iZQD1e5ya-7L","colab_type":"code","colab":{}},"source":["// This code comes from the Swift-Models repo, from the TF team.\n","\n","// Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//     http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","public struct DatasetUtilities {\n","    public static let curentWorkingDirectoryURL = URL(\n","        fileURLWithPath: FileManager.default.currentDirectoryPath)\n","\n","    public static func fetchResource(\n","        filename: String,\n","        remoteRoot: URL,\n","        localStorageDirectory: URL = curentWorkingDirectoryURL\n","    ) -> Data {\n","        print(\"Loading resource: \\(filename)\")\n","\n","        let resource = ResourceDefinition(\n","            filename: filename,\n","            remoteRoot: remoteRoot,\n","            localStorageDirectory: localStorageDirectory)\n","\n","        let localURL = resource.localURL\n","\n","        if !FileManager.default.fileExists(atPath: localURL.path) {\n","            print(\n","                \"File does not exist locally at expected path: \\(localURL.path) and must be fetched\"\n","            )\n","            fetchFromRemoteAndSave(resource)\n","        }\n","\n","        do {\n","            print(\"Loading local data at: \\(localURL.path)\")\n","            let data = try Data(contentsOf: localURL)\n","            print(\"Succesfully loaded resource: \\(filename)\")\n","            return data\n","        } catch {\n","            fatalError(\"Failed to contents of resource: \\(localURL)\")\n","        }\n","    }\n","\n","    struct ResourceDefinition {\n","        let filename: String\n","        let remoteRoot: URL\n","        let localStorageDirectory: URL\n","\n","        var localURL: URL {\n","            localStorageDirectory.appendingPathComponent(filename)\n","        }\n","\n","        var remoteURL: URL {\n","            remoteRoot.appendingPathComponent(filename).appendingPathExtension(\"gz\")\n","        }\n","\n","        var archiveURL: URL {\n","            localURL.appendingPathExtension(\"gz\")\n","        }\n","    }\n","\n","    static func fetchFromRemoteAndSave(_ resource: ResourceDefinition) {\n","        let remoteLocation = resource.remoteURL\n","        let archiveLocation = resource.archiveURL\n","\n","        do {\n","            print(\"Fetching URL: \\(remoteLocation)...\")\n","            let archiveData = try Data(contentsOf: remoteLocation)\n","            print(\"Writing fetched archive to: \\(archiveLocation.path)\")\n","            try archiveData.write(to: archiveLocation)\n","        } catch {\n","            fatalError(\"Failed to fetch and save resource with error: \\(error)\")\n","        }\n","        print(\"Archive saved to: \\(archiveLocation.path)\")\n","\n","        extractArchive(for: resource)\n","    }\n","\n","    static func extractArchive(for resource: ResourceDefinition) {\n","        print(\"Extracting archive...\")\n","\n","        let archivePath = resource.archiveURL.path\n","\n","        #if os(macOS)\n","            let gunzipLocation = \"/usr/bin/gunzip\"\n","        #else\n","            let gunzipLocation = \"/bin/gunzip\"\n","        #endif\n","\n","        let task = Process()\n","        task.executableURL = URL(fileURLWithPath: gunzipLocation)\n","        task.arguments = [archivePath]\n","        do {\n","            try task.run()\n","            task.waitUntilExit()\n","        } catch {\n","            fatalError(\"Failed to extract \\(archivePath) with error: \\(error)\")\n","        }\n","    }\n","}\n","\n","\n","public struct MNIST {\n","    public let trainingImages: Tensor<Float>\n","    public let trainingLabels: Tensor<Int32>\n","    public let testImages: Tensor<Float>\n","    public let testLabels: Tensor<Int32>\n","\n","    public let trainingSize: Int\n","    public let testSize: Int\n","\n","    public let batchSize: Int\n","\n","    public init(\n","        batchSize: Int, flattening: Bool = false, normalizing: Bool = false,\n","        localStorageDirectory: URL = DatasetUtilities.curentWorkingDirectoryURL\n","    ) {\n","        self.batchSize = batchSize\n","\n","        let (trainingImages, trainingLabels) = fetchDataset(\n","            localStorageDirectory: localStorageDirectory,\n","            imagesFilename: \"train-images-idx3-ubyte\",\n","            labelsFilename: \"train-labels-idx1-ubyte\",\n","            flattening: flattening,\n","            normalizing: normalizing)\n","\n","        self.trainingImages = trainingImages\n","        self.trainingLabels = trainingLabels\n","        self.trainingSize = Int(trainingLabels.shape[0])\n","\n","        let (testImages, testLabels) = fetchDataset(\n","            localStorageDirectory: localStorageDirectory,\n","            imagesFilename: \"t10k-images-idx3-ubyte\",\n","            labelsFilename: \"t10k-labels-idx1-ubyte\",\n","            flattening: flattening,\n","            normalizing: normalizing)\n","        self.testImages = testImages\n","        self.testLabels = testLabels\n","        self.testSize = Int(testLabels.shape[0])\n","    }\n","}\n","\n","extension Tensor {\n","    public func minibatch(at index: Int, batchSize: Int) -> Tensor {\n","        let start = index * batchSize\n","        return self[start..<start+batchSize]\n","    }\n","}\n","\n","fileprivate func fetchDataset(\n","    localStorageDirectory: URL,\n","    imagesFilename: String,\n","    labelsFilename: String,\n","    flattening: Bool,\n","    normalizing: Bool\n",") -> (images: Tensor<Float>, labels: Tensor<Int32>) {\n","    guard let remoteRoot: URL = URL(string: \"http://yann.lecun.com/exdb/mnist\") else {\n","        fatalError(\"Failed to create MNST root url: http://yann.lecun.com/exdb/mnist\")\n","    }\n","\n","    let imagesData = DatasetUtilities.fetchResource(\n","        filename: imagesFilename,\n","        remoteRoot: remoteRoot,\n","        localStorageDirectory: localStorageDirectory)\n","    let labelsData = DatasetUtilities.fetchResource(\n","        filename: labelsFilename,\n","        remoteRoot: remoteRoot,\n","        localStorageDirectory: localStorageDirectory)\n","\n","    let images = [UInt8](imagesData).dropFirst(16).map(Float.init)\n","    let labels = [UInt8](labelsData).dropFirst(8).map(Int32.init)\n","\n","    let rowCount = labels.count\n","    let (imageWidth, imageHeight) = (28, 28)\n","\n","    if flattening {\n","        var flattenedImages = Tensor(shape: [rowCount, imageHeight * imageWidth], scalars: images)\n","            / 255.0\n","        if normalizing {\n","            flattenedImages = flattenedImages * 2.0 - 1.0\n","        }\n","        return (images: flattenedImages, labels: Tensor(labels))\n","    } else {\n","        return (\n","            images:\n","                Tensor(shape: [rowCount, 1, imageHeight, imageWidth], scalars: images)\n","                    .transposed(withPermutations: [0, 2, 3, 1]) / 255,  // NHWC\n","            labels: Tensor(labels)\n","        )\n","    }\n","}\n","\n","public func createDirectoryIfMissing(at path: String) throws {\n","    guard !FileManager.default.fileExists(atPath: path) else { return }\n","    try FileManager.default.createDirectory(\n","        atPath: path,\n","        withIntermediateDirectories: false,\n","        attributes: nil)\n","}\n","\n","\n","public struct Image {\n","    public enum ByteOrdering {\n","        case bgr\n","        case rgb\n","    }\n","\n","    enum ImageTensor {\n","        case float(data: Tensor<Float>)\n","        case uint8(data: Tensor<UInt8>)\n","    }\n","\n","    let imageData: ImageTensor\n","\n","    public init(tensor: Tensor<UInt8>) {\n","        self.imageData = .uint8(data: tensor)\n","    }\n","\n","    public init(tensor: Tensor<Float>) {\n","        self.imageData = .float(data: tensor)\n","    }\n","\n","    public init(jpeg url: URL, byteOrdering: ByteOrdering = .rgb) {\n","        let loadedFile = Raw.readFile(filename: StringTensor(url.absoluteString))\n","        let loadedJpeg = Raw.decodeJpeg(contents: loadedFile, channels: 3, dctMethod: \"\")\n","        if byteOrdering == .bgr {\n","            self.imageData = .uint8(\n","                data: Raw.reverse(loadedJpeg, dims: Tensor<Bool>([false, false, false, true])))\n","        } else {\n","            self.imageData = .uint8(data: loadedJpeg)\n","        }\n","    }\n","\n","    public func save(to url: URL, quality: Int64 = 95) {\n","        // This currently only saves in grayscale.\n","        let outputImageData: Tensor<UInt8>\n","        switch self.imageData {\n","        case let .uint8(data): outputImageData = data\n","        case let .float(data):\n","            let lowerBound = data.min(alongAxes: [0, 1])\n","            let upperBound = data.max(alongAxes: [0, 1])\n","            let adjustedData = (data - lowerBound) * (255.0 / (upperBound - lowerBound))\n","            outputImageData = Tensor<UInt8>(adjustedData)\n","        }\n","\n","        let encodedJpeg = Raw.encodeJpeg(\n","            image: outputImageData, format: .grayscale, quality: quality, xmpMetadata: \"\")\n","        Raw.writeFile(filename: StringTensor(url.absoluteString), contents: encodedJpeg)\n","    }\n","\n","    public func resized(to size: (Int, Int)) -> Image {\n","        switch self.imageData {\n","        case let .uint8(data):\n","            return Image(\n","                tensor: Raw.resizeBilinear(\n","                    images: Tensor<UInt8>([data]),\n","                    size: Tensor<Int32>([Int32(size.0), Int32(size.1)])))\n","        case let .float(data):\n","            return Image(\n","                tensor: Raw.resizeBilinear(\n","                    images: Tensor<Float>([data]),\n","                    size: Tensor<Int32>([Int32(size.0), Int32(size.1)])))\n","        }\n","\n","    }\n","}\n","\n","public func saveImage(_ tensor: Tensor<Float>, size: (Int, Int), directory: String, name: String) throws {\n","    try createDirectoryIfMissing(at: directory)\n","    let reshapedTensor = tensor.reshaped(to: [size.0, size.1, 1])\n","    let image = Image(tensor: reshapedTensor)\n","    let outputURL = URL(fileURLWithPath:\"\\(directory)\\(name).jpg\")\n","    image.save(to: outputURL)\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-s10JC3icx_z","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1DhL7o5AaV11","colab_type":"text"},"source":["## Parameters"]},{"cell_type":"markdown","metadata":{"id":"DNBBx3praV12","colab_type":"text"},"source":["Our parameters are as follows:\n","\n","* `epochCount` is how many epochs it should train for. 10 is a good number to get a reasonable GAN in this case.\n","* `batchSize` is the size of a batch that we're going to ask the MNIST dataset for.\n","* `outputFolder` defines the output folder where we'll be writing things on the file system.\n","* `imageHeight` and `imageWidth`, together with `imageSize` define the output imagesize that the Generator will make, as well as (naturally) the input image size the Discriminator will take.\n","* `latentSize` defines the latent representation size used by the Generator to generate.\n","* `testImageGridSize` defines the size of the grid of images that we'll generate to look at the result of the GAN."]},{"cell_type":"code","metadata":{"id":"mwmHgWNSaV13","colab_type":"code","colab":{}},"source":["let epochCount = 10\n","let batchSize = 32\n","let outputFolder = \"./MNIST_GAN_Output/\"\n","let imageHeight = 28\n","let imageWidth = 28\n","let imageSize = imageHeight * imageWidth\n","let latentSize = 64\n","let testImageGridSize = 4"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7nVbPqOITi5T","colab_type":"text"},"source":["## Convenience helper to save an image grid"]},{"cell_type":"code","metadata":{"id":"FtGlyeViTlEa","colab_type":"code","colab":{}},"source":["func saveImageGrid(_ testImage: Tensor<Float>, name: String) throws {\n","    var gridImage = testImage.reshaped(\n","        to: [\n","            testImageGridSize, testImageGridSize,\n","            imageHeight, imageWidth,\n","        ])\n","\n","    // Add padding.\n","    gridImage = gridImage.padded(forSizes: [(0, 0), (0, 0), (1, 1), (1, 1)], with: 1)\n","\n","    // Transpose to create single image.\n","    gridImage = gridImage.transposed(withPermutations: [0, 2, 1, 3])\n","    gridImage = gridImage.reshaped(\n","        to: [\n","            (imageHeight + 2) * testImageGridSize,\n","            (imageWidth + 2) * testImageGridSize,\n","        ])\n","        \n","    // Convert [-1, 1] range to [0, 1] range.\n","    gridImage = (gridImage + 1) / 2\n","\n","    try saveImage(\n","        gridImage, size: (gridImage.shape[0], gridImage.shape[1]), directory: outputFolder,\n","        name: name)\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bccfwHeLaV18","colab_type":"text"},"source":["# Generator Model"]},{"cell_type":"markdown","metadata":{"id":"3M52cWDbaV19","colab_type":"text"},"source":["Our `Generator` is a `Struct` adhering to the  [`Layer` Protocol](https://www.tensorflow.org/swift/api_docs/Protocols/Layer) (which is part of Swift For TensorFlow's API). The Generator has the following layers:\n","\n","* `dense1`, a `Dense` layer (a [densely-connected layer](https://www.tensorflow.org/swift/api_docs/Structs/Dense)) that takes an `inputSize` of `latentSize` (defined earlier), and an `outputSize` of `latentSize*2`. The `activation` function determines the output shape of each node in the layer. There are many available activations, but [ReLU](https://www.tensorflow.org/swift/api_docs/Functions#leakyrelu_:alpha:) is common for hidden layers.\n","\n","* `dense2` is likewise, but with an `inputSize` of `latentSize*2` (taking the output of the previous layer), and an `outputSize` of `latestSize*4`.\n","\n","* `dense3` is likewise, taking the previous output as input, and outputting it larger.\n","\n","* `dense4` is, again, the same, but has an `outputSize` of `imageSize` instead (our final desired image size). It uses [tanh](https://www.tensorflow.org/swift/api_docs/Functions#tanh_:) as its activation, tanh (hyperbolic tangent) is sigmoidal (s-shaped) and outputs values that range from -1 to 1.\n","\n","* three [`BatchNorm`]() layers, `batchnorm1`, `batchnorm2`, `batchnorm3`, that normalise the activations of the previous layer at each batch by applying transformations that maintain the mean activation close to 0 and the activation standard deviation close to 1. `featureCount` is the number of features.\n","    \n","Finally, we have our `callAsFunction()` method, which sequences through the `Dense` layers, using the `BatchNorm` layers to normalise, before finally returning the output of the fourth and final `Dense` layer.\n","\n","\n","\n","    "]},{"cell_type":"code","metadata":{"id":"vrqazoRDaV1-","colab_type":"code","colab":{}},"source":["struct Generator: Layer {\n","    var dense1 = Dense<Float>(\n","        inputSize: latentSize, outputSize: latentSize * 2,\n","        activation: { leakyRelu($0) })\n","\n","    var dense2 = Dense<Float>(\n","        inputSize: latentSize * 2, outputSize: latentSize * 4,\n","        activation: { leakyRelu($0) })\n","\n","    var dense3 = Dense<Float>(\n","        inputSize: latentSize * 4, outputSize: latentSize * 8,\n","        activation: { leakyRelu($0) })\n","\n","    var dense4 = Dense<Float>(\n","        inputSize: latentSize * 8, outputSize: imageSize,\n","        activation: tanh)\n","\n","    var batchnorm1 = BatchNorm<Float>(featureCount: latentSize * 2)\n","    var batchnorm2 = BatchNorm<Float>(featureCount: latentSize * 4)\n","    var batchnorm3 = BatchNorm<Float>(featureCount: latentSize * 8)\n","\n","    @differentiable\n","    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n","        let x1 = batchnorm1(dense1(input))\n","        let x2 = batchnorm2(dense2(x1))\n","        let x3 = batchnorm3(dense3(x2))\n","        return dense4(x3)\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sHI61VGCaV2D","colab_type":"text"},"source":["## Discriminator Model"]},{"cell_type":"markdown","metadata":{"id":"vzRnmzTBaV2E","colab_type":"text"},"source":["Our `Discriminator` is a `Struct` adhering to the `Layer` Protocol. The `Discriminator` has the following layers:\n","\n","* `dense1`, a `Dense` layer, taking an `inputSize` of `imageSize`, outputting an `outputSize` of 256. It also uses ReLU for activation.\n","\n","* `dense2` and `dense3`, which take an `inputSize` and `outputSize` of 256 and 64, and 64 and 16, respectively, also using ReLU.\n","\n","* `dense4`, which takes the `inputSize` of 16, and has an `outputSize` of 1, and using `identity` as the activation (just linear).\n","\n","Finally, we have our `callAsFunction()` method, which just sequences the input through the four (`Dense`) layers."]},{"cell_type":"code","metadata":{"id":"QYpSCYd1aV2F","colab_type":"code","colab":{}},"source":["struct Discriminator: Layer {\n","    var dense1 = Dense<Float>(\n","        inputSize: imageSize, outputSize: 256,\n","        activation: { leakyRelu($0) })\n","\n","    var dense2 = Dense<Float>(\n","        inputSize: 256, outputSize: 64,\n","        activation: { leakyRelu($0) })\n","\n","    var dense3 = Dense<Float>(\n","        inputSize: 64, outputSize: 16,\n","        activation: { leakyRelu($0) })\n","\n","    var dense4 = Dense<Float>(\n","        inputSize: 16, outputSize: 1,\n","        activation: identity)\n","\n","    @differentiable\n","    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n","        input.sequenced(through: dense1, dense2, dense3, dense4)\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VD1eoCIkaV2J","colab_type":"text"},"source":["## Loss functions"]},{"cell_type":"markdown","metadata":{"id":"j9J4gWIFaV2K","colab_type":"text"},"source":["### Discriminator Loss Function"]},{"cell_type":"markdown","metadata":{"id":"8cWfh4Y8aV2L","colab_type":"text"},"source":["Our `discriminatorLoss()` function, which takes both the real and fake [logits](https://datascience.stackexchange.com/a/31045), and returns the `realLoss` and `fakeLoss`, via the `sigmoidCrossEntropy()` function. That's it!"]},{"cell_type":"code","metadata":{"id":"zwjx0LbSaV2M","colab_type":"code","colab":{}},"source":["@differentiable\n","func discriminatorLoss(realLogits: Tensor<Float>, fakeLogits: Tensor<Float>) -> Tensor<Float> {\n","    let realLoss = sigmoidCrossEntropy(\n","        logits: realLogits,\n","        labels: Tensor(ones: realLogits.shape))\n","    let fakeLoss = sigmoidCrossEntropy(\n","        logits: fakeLogits,\n","        labels: Tensor(zeros: fakeLogits.shape))\n","    return realLoss + fakeLoss\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHzdj9kbaV2Q","colab_type":"text"},"source":["### Generator Loss Function"]},{"cell_type":"markdown","metadata":{"id":"QFn5eBEwaV2R","colab_type":"text"},"source":["Our `generatorLoss()` function takes the fake logits, and calculates the `sigmoidCrossEntropy()`."]},{"cell_type":"code","metadata":{"id":"h9uAagmqaV2S","colab_type":"code","colab":{}},"source":["@differentiable\n","func generatorLoss(fakeLogits: Tensor<Float>) -> Tensor<Float> {\n","    sigmoidCrossEntropy(\n","        logits: fakeLogits,\n","        labels: Tensor(ones: fakeLogits.shape))\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4Hai3lkCaV2W","colab_type":"text"},"source":["### Random Samples"]},{"cell_type":"markdown","metadata":{"id":"wz9iK6u-aV2X","colab_type":"text"},"source":["Our `sampleVector()` function returns random stuff, that we use for both the Discriminator and Generator later on."]},{"cell_type":"code","metadata":{"id":"DnIT9U4qaV2Y","colab_type":"code","colab":{}},"source":["/// Returns `size` samples of noise vector.\n","func sampleVector(size: Int) -> Tensor<Float> {\n","    Tensor(randomNormal: [size, latentSize])\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tpkVE3qZaV2a","colab_type":"text"},"source":["## Setting up to train"]},{"cell_type":"markdown","metadata":{"id":"QdDB8KtZaV2b","colab_type":"text"},"source":["### Getting a dataset"]},{"cell_type":"markdown","metadata":{"id":"Lkg4MrEbaV2c","colab_type":"text"},"source":["We're going to use the \"Hello, world!\" of machine learning, MNIST, as our dataset. This comes from some of the helper libraries we've provided for this session (which, in turn, are largely drawn from deep in the bowels of the TensorFlow project):"]},{"cell_type":"code","metadata":{"id":"DdzHFPKFaV2d","colab_type":"code","outputId":"1b42a039-2680-4a6d-beea-da01ccb9bee5","executionInfo":{"status":"ok","timestamp":1572298964152,"user_tz":240,"elapsed":28051,"user":{"displayName":"Paris B-A","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATPYgh7Oradnt-89Tt0-SyerXDc8Z985jmLS2U=s64","userId":"01326454337734597812"}},"colab":{"base_uri":"https://localhost:8080/","height":583}},"source":["let dataset = MNIST(batchSize: batchSize, flattening: true, normalizing: true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading resource: train-images-idx3-ubyte\r\n","File does not exist locally at expected path: /content/train-images-idx3-ubyte and must be fetched\r\n","Fetching URL: http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz...\n","Writing fetched archive to: /content/train-images-idx3-ubyte.gz\n","Archive saved to: /content/train-images-idx3-ubyte.gz\n","Extracting archive...\n","Loading local data at: /content/train-images-idx3-ubyte\n","Succesfully loaded resource: train-images-idx3-ubyte\n","Loading resource: train-labels-idx1-ubyte\n","File does not exist locally at expected path: /content/train-labels-idx1-ubyte and must be fetched\n","Fetching URL: http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz...\n","Writing fetched archive to: /content/train-labels-idx1-ubyte.gz\n","Archive saved to: /content/train-labels-idx1-ubyte.gz\n","Extracting archive...\n","Loading local data at: /content/train-labels-idx1-ubyte\n","Succesfully loaded resource: train-labels-idx1-ubyte\n","Loading resource: t10k-images-idx3-ubyte\n","File does not exist locally at expected path: /content/t10k-images-idx3-ubyte and must be fetched\n","Fetching URL: http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz...\n","Writing fetched archive to: /content/t10k-images-idx3-ubyte.gz\n","Archive saved to: /content/t10k-images-idx3-ubyte.gz\n","Extracting archive...\n","Loading local data at: /content/t10k-images-idx3-ubyte\n","Succesfully loaded resource: t10k-images-idx3-ubyte\n","Loading resource: t10k-labels-idx1-ubyte\n","File does not exist locally at expected path: /content/t10k-labels-idx1-ubyte and must be fetched\n","Fetching URL: http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz...\n","Writing fetched archive to: /content/t10k-labels-idx1-ubyte.gz\n","Archive saved to: /content/t10k-labels-idx1-ubyte.gz\n","Extracting archive...\n","Loading local data at: /content/t10k-labels-idx1-ubyte\n","Succesfully loaded resource: t10k-labels-idx1-ubyte\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7tzuMHzIaV2g","colab_type":"text"},"source":["### Creating a generator and a discriminator"]},{"cell_type":"code","metadata":{"id":"NX939dWAaV2h","colab_type":"code","colab":{}},"source":["var generator = Generator()\n","var discriminator = Discriminator()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nY07PtXvaV2l","colab_type":"text"},"source":["### Creating optimisers for the generator and the discriminator"]},{"cell_type":"markdown","metadata":{"id":"SyHqhL4daV2l","colab_type":"text"},"source":["We need an optimization algorithm for both the models. In each case, we'll use the [Adam](https://www.tensorflow.org/swift/api_docs/Classes/Adam) optimisation algorithm. It's a popular choice!"]},{"cell_type":"markdown","metadata":{"id":"aAloZrVscDxi","colab_type":"text"},"source":["#### Generator's optimizer"]},{"cell_type":"code","metadata":{"id":"kUEvej91aV2m","colab_type":"code","colab":{}},"source":["let optG = Adam(for: generator, learningRate: 2e-4, beta1: 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qRmW0oJJcHx5","colab_type":"text"},"source":["#### Discriminator's optimizer"]},{"cell_type":"code","metadata":{"id":"Xp54ZtpOcKIT","colab_type":"code","colab":{}},"source":["let optD = Adam(for: discriminator, learningRate: 2e-4, beta1: 0.5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5VjtOMYlaV2t","colab_type":"text"},"source":["## Training and Inference"]},{"cell_type":"markdown","metadata":{"id":"FHy5C76Zc8nV","colab_type":"text"},"source":["First, we'll print out a message to say we're starting training:"]},{"cell_type":"code","metadata":{"id":"BM099DZAc-UE","colab_type":"code","outputId":"314d0bd9-e339-49cd-9ae9-11190864d0b7","executionInfo":{"status":"ok","timestamp":1572298965076,"user_tz":240,"elapsed":28924,"user":{"displayName":"Paris B-A","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATPYgh7Oradnt-89Tt0-SyerXDc8Z985jmLS2U=s64","userId":"01326454337734597812"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(\"GAN: Training Begins\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GAN: Training Begins\r\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8trm-rcJc_MR","colab_type":"text"},"source":["To train, we iterate through to our desired `epochCount`, runs training using both the Generator and the Discriminator, and then runs an inference to generate a grid of images and print out the current epoch, and the generator's loss:\n","\n","Specifically, in each epoch, we:\n","* set the [`Context`](https://www.tensorflow.org/swift/api_docs/Structs/Context) to `.training` so that, for example, `BatchNorm` layers (like we're using in our Generator) will compute mean and variance when applied to inputs\n","* iterate through the training data batch and:\n","  * create a random sample using the `sampleVector()` function we wrote earlier\n","  * for the generator's gradient (ùõÅ), use the random sample and the output of the discriminator using that random sample to calculate a loss using the `generatorLoss()` function we wrote earlier\n","  * update the generator model, along the generator gradient, using the generator's optimizer\n","  * get a batch of of real images from the training data, as well as another random sample using `sampleVector()`, and use the generator to generate some generated (aka fake) images using the random sample data\n","  * for the discriminator's gradient (ùõÅ), calculate and return the loss between the generator running on the real images and on the fake images\n","  * update the discriminator model, along the discriminator gradient, using the discriminator's optimizer\n","* after iterating through the  training data batch, we set the [`Context`](https://www.tensorflow.org/swift/api_docs/Structs/Context) to `.inferece`\n","* then (after training for that epoch) we generate a test image, using the generator and random sample of the size our parameters dictate for the test image grid\n","  * and attempt to save that test image, using one of our convenience functions, `saveImageGrid()`\n","* we then check the loss on the generator for the test image, with our `generatorLoss()` function\n","* and print out the current epoch and generator loss"]},{"cell_type":"code","metadata":{"id":"ArTjDq3RaV2v","colab_type":"code","outputId":"20dd4423-b705-4d87-c5de-d6e65366761d","executionInfo":{"status":"ok","timestamp":1572300017891,"user_tz":240,"elapsed":1081728,"user":{"displayName":"Paris B-A","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mATPYgh7Oradnt-89Tt0-SyerXDc8Z985jmLS2U=s64","userId":"01326454337734597812"}},"colab":{"base_uri":"https://localhost:8080/","height":194}},"source":["for epoch in 1...epochCount {\n","\n","    Context.local.learningPhase = .training\n","\n","    for i in 0 ..< dataset.trainingSize / batchSize {\n","        // Perform alternative update.\n","        // Update generator.\n","        let vec1 = sampleVector(size: batchSize)\n","\n","        let ùõÅgenerator = generator.gradient { generator -> Tensor<Float> in\n","            let fakeImages = generator(vec1)\n","            let fakeLogits = discriminator(fakeImages)\n","            let loss = generatorLoss(fakeLogits: fakeLogits)\n","            return loss\n","        }\n","        optG.update(&generator, along: ùõÅgenerator)\n","\n","        // Update discriminator.\n","        let realImages = dataset.trainingImages.minibatch(at: i, batchSize: batchSize)\n","        let vec2 = sampleVector(size: batchSize)\n","        let fakeImages = generator(vec2)\n","\n","        let ùõÅdiscriminator = discriminator.gradient { discriminator -> Tensor<Float> in\n","            let realLogits = discriminator(realImages)\n","            let fakeLogits = discriminator(fakeImages)\n","            let loss = discriminatorLoss(realLogits: realLogits, fakeLogits: fakeLogits)\n","            return loss\n","        }\n","        optD.update(&discriminator, along: ùõÅdiscriminator)\n","    }\n","\n","    // Start inference phase.\n","    Context.local.learningPhase = .inference\n","    let testImage = generator(sampleVector(size: testImageGridSize * testImageGridSize))\n","\n","    do {\n","        try saveImageGrid(testImage, name: \"epoch-\\(epoch)-output\")\n","    } catch {\n","        print(\"Could not save image grid with error: \\(error)\")\n","    }\n","\n","    let lossG = generatorLoss(fakeLogits: testImage)\n","    print(\"Current Epoch: \\(epoch) | Generator Loss: \\(lossG)\")\n","}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Current Epoch: 1 | Generator Loss: 1.1418108\n","Current Epoch: 2 | Generator Loss: 1.1449372\n","Current Epoch: 3 | Generator Loss: 1.1592628\n","Current Epoch: 4 | Generator Loss: 1.1639445\n","Current Epoch: 5 | Generator Loss: 1.1449314\n","Current Epoch: 6 | Generator Loss: 1.1559143\n","Current Epoch: 7 | Generator Loss: 1.1588637\n","Current Epoch: 8 | Generator Loss: 1.1727781\n","Current Epoch: 9 | Generator Loss: 1.1668153\n","Current Epoch: 10 | Generator Loss: 1.1905712\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BvC2vj3-jxHs","colab_type":"text"},"source":["## Extra Credit"]},{"cell_type":"markdown","metadata":{"id":"RCIu9uc4jy7Z","colab_type":"text"},"source":["Our suggestions for what to do next:\n","\n","\n","1. use a Python library to visualise some of this in the notebook, either via graphs, or via displaying images inline in the notebook\n","2. modify the GAN to be able to generate one image of a digit at a time, upon request (e.g. make a function that lets you request a generated 5, or a generated 6)\n","3. modify the GAN to generate something other than MNIST digits \n","\n"]}]}